{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "from Bio import SeqIO\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "from datetime import datetime\n",
    "\n",
    "# SETTING\n",
    "pixel_max = 254 #Customerization\n",
    "\n",
    "# CHANNEL 0: BASE\n",
    "base_color_stride = 70 #Customerization\n",
    "offset_a_g = 40 #Customerization\n",
    "offset_t_c = 30 #Customerization\n",
    "\n",
    "# CHANNEL 1: BASE QUALITY\n",
    "default_quality = 0\n",
    "base_quality_cap = 40\n",
    "\n",
    "# CHANNEL 2: MAPPING QUALITY\n",
    "mapping_set_empty = 0 #Customerization\n",
    "mapping_quality_cap = 60 #Customerization\n",
    "\n",
    "# CHANNEL 3: ON POSITIVE STRAND\n",
    "set_empty = 0 #Customerization\n",
    "positive_strand = 70 #Customerization\n",
    "negative_strand = 240 #Customerization\n",
    "\n",
    "# CHANNEL 4: MATCH REFERENCE\n",
    "pixel_max = 254 #Customerization\n",
    "not_match_ref = pixel_max * 1 #Customerization\n",
    "match_ref = pixel_max * 0.2 #Customerization\n",
    "ref_not_provided = 255 #Customerization\n",
    "\n",
    "# TO RGB\n",
    "pixel_max_empty_def = 255\n",
    "\n",
    "\n",
    "'''\n",
    "Color encoding\n",
    "'''\n",
    "# CHANNEL 1: Base quality\n",
    "def base_to_color_full_array_input(x):\n",
    "    A = base_color_stride * 3 + offset_a_g\n",
    "    T = base_color_stride * 2 + offset_t_c\n",
    "    C = base_color_stride * 1 + offset_t_c\n",
    "    G = base_color_stride * 0 + offset_a_g\n",
    "    empty_to_fill = np.zeros(x.shape, dtype = np.int16)\n",
    "    empty_to_fill[x == \"A\"] = A\n",
    "    empty_to_fill[x == \"T\"] = T\n",
    "    empty_to_fill[x == \"C\"] = C\n",
    "    empty_to_fill[x == \"G\"] = G\n",
    "    empty_to_fill[x == \"a\"] = A\n",
    "    empty_to_fill[x == \"t\"] = T\n",
    "    empty_to_fill[x == \"c\"] = C\n",
    "    empty_to_fill[x == \"g\"] = G\n",
    "    empty_to_fill[x == \"N\"] = 0\n",
    "    empty_to_fill[x == \"D\"] = 0\n",
    "    return empty_to_fill\n",
    "\n",
    "# CHANNEL 2: Mapping quality\n",
    "def mapping_quality_fill(array, mapping_quality):\n",
    "    \n",
    "    to_fill = min(mapping_quality, mapping_quality_cap) / mapping_quality_cap * pixel_max\n",
    "    mapping_quality_temp = np.full(array.shape, mapping_set_empty, dtype = np.int16)\n",
    "    mapping_quality_temp[array != \"\"] = to_fill\n",
    "    mapping_quality_temp[array == \"N\"] = mapping_set_empty\n",
    "    mapping_quality_temp[array == \"D\"] = mapping_set_empty\n",
    "    \n",
    "    return mapping_quality_temp\n",
    "    \n",
    "\n",
    "# CHANNEL 3: On positive strand\n",
    "def on_positive_strand_fill(array, positive_flag):\n",
    "    \n",
    "    on_positive_strand_temp = np.full(array.shape, set_empty, dtype = np.int16)\n",
    "    to_fill = positive_strand\n",
    "\n",
    "    binary_flag = np.binary_repr(positive_flag)\n",
    "    if (len(binary_flag) >= 5) and (list(binary_flag)[-5] == \"1\"):\n",
    "        to_fill = negative_strand\n",
    "    \n",
    "    on_positive_strand_temp[array != \"\"] = to_fill\n",
    "    on_positive_strand_temp[array == \"N\"] = set_empty\n",
    "    on_positive_strand_temp[array == \"D\"] = set_empty\n",
    "\n",
    "    return on_positive_strand_temp\n",
    "\n",
    "\n",
    "# CHANNEL 4: Match reference\n",
    "def match_ref_fill(depth, window, array):\n",
    "    \n",
    "    empty = np.full((depth, window), ref_not_provided, dtype = np.int16)\n",
    "    for i in np.arange(0, array.shape[1]):\n",
    "        for j in np.arange(1, array.shape[0]):\n",
    "            if array[j,i] == \"\":\n",
    "                break\n",
    "            elif array[j,i] == \"N\":\n",
    "                if array[0,i] == \"N\":\n",
    "                    break\n",
    "                else:\n",
    "                    empty[j,i] = not_match_ref\n",
    "            elif array[j,i] == array[0,i]:\n",
    "                empty[j,i] = match_ref\n",
    "            else:\n",
    "                empty[j,i] = ref_not_provided\n",
    "    return empty\n",
    "\n",
    "\n",
    "# COMBINE CHANNEL TO RGB\n",
    "def channels_to_RGB(pixel_max_empty_def,\n",
    "                    pre_image_base_color, \n",
    "                    pre_image_mapping_quality):\n",
    "    pre_image_mapping_quality[:,0,:] = pixel_max_empty_def\n",
    "    alpha = pre_image_mapping_quality / pixel_max_empty_def\n",
    "    #np.multiply(pre_image_base_color, alpha)\n",
    "\n",
    "    RGB = np.empty((pre_image_base_color.shape[0],pre_image_base_color.shape[1],pre_image_base_color.shape[2]), dtype = np.int16)\n",
    "    RGB[:,:,:] = np.multiply(pre_image_base_color, alpha)\n",
    "    return RGB\n",
    "\n",
    "def consecutive(data, stepsize=1):\n",
    "    return np.split(data, np.where(np.diff(data) != stepsize)[0]+1)\n",
    "\n",
    "def make_list_of_searching_interval_of_scaffold(scaffold_length, to_use_selected_scaffold_df):\n",
    "    mask = np.zeros(scaffold_length, dtype = bool)\n",
    "    searching_interval_selected = np.arange(1,(scaffold_length + 1))\n",
    "    searching_locus_list = pd.Series([np.arange(a, b) for a, b in zip(to_use_selected_scaffold_df[\"expand start\"], (to_use_selected_scaffold_df[\"expand end\"] + 1))], to_use_selected_scaffold_df.index)\n",
    "    for locus in searching_locus_list:\n",
    "        mask[locus] = True\n",
    "    searching_interval_unoverlapped = searching_interval_selected[mask]\n",
    "\n",
    "    return consecutive(searching_interval_unoverlapped)\n",
    "\n",
    "'''\n",
    "Preprocessing\n",
    "'''\n",
    "def cigar_to_list(cigar): # NOT NEED TO USE THIS! THIS FUNCTION IS INCLUDED IN refine_read_by_cigar BELOW\n",
    "    '''\n",
    "    Deal with cigar \n",
    "    Split an unsplit cigar list to separated cigar array by number of each condition.\n",
    "    \n",
    "    2M3S1D2I to MMSSSDII\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    cigar : list\n",
    "        One element unseperated cigar list.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cigar_list : 1D numpy array\n",
    "        A array of cigar.\n",
    "    '''\n",
    "        \n",
    "    separate = np.array([s.strip() for s in re.split(r\"(\\D+)\", cigar)]) # Separate one element cigar list by cigar char \n",
    "    if separate[-1] == \"\": # Delete last empty element if it exists\n",
    "        separate = separate[:-1]\n",
    "\n",
    "\n",
    "    number = separate[::2].astype(int) # Extract number of each cigar\n",
    "    cigar = separate[1::2] # Extract char of cigar\n",
    "\n",
    "    # Cheack if number of elements in two list are same\n",
    "    if len(number) != len(cigar): \n",
    "        print(\"elements are not the same\")\n",
    "\n",
    "    # If number of elements are same, make a array of cigar\n",
    "    else:\n",
    "        cigar_list = []\n",
    "        for i in np.arange(0,len(number)):\n",
    "            for j in np.arange(0,number[i]):\n",
    "                cigar_list.append(cigar[i])\n",
    "        cigar_list = np.array(cigar_list)\n",
    "    \n",
    "    return cigar_list\n",
    "\n",
    "def refine_read_by_cigar(read, cigar): #PLEASE USE THIE TO MAKE REFINED READ FOR ALIGNMENT\n",
    "    '''\n",
    "    To refine reads by cigar list one by one.\n",
    "    \n",
    "    S : Directly delete it and move the behind forward\n",
    "    I : Extract to make a list of inserted element with position and delete it, moving the behind forward\n",
    "    D : Fill \"D\" in reads, move the behind backward\n",
    "    N : Fill \"N\" in reads, move the behind backward\n",
    "    M : Unchange\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    read : list\n",
    "        One element unseperated read list.\n",
    "    cigar : list\n",
    "        One element unseperated cigar list.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    refined_read : list\n",
    "        unseparated list of refined-read\n",
    "        \n",
    "    refined_read_insert : 1D numpy array\n",
    "        the inserted element\n",
    "    \n",
    "    refined_read_insert_index_at_ori_read : 1D numpy array\n",
    "        the index of inserted element in the original read (from 0)\n",
    "    \n",
    "    refined_read_insert_index_at_refined_read : 1D numpy array\n",
    "        the index of where to insert the inserted element on refined read (from 0)\n",
    "    '''\n",
    "    cigar_temp_list = cigar_to_list(cigar) # Read cigar and make cigar list by cigar_to_list function\n",
    "    read_temp_list = np.array(list(read)) # Make list of read\n",
    "\n",
    "    refined_read = [] # Make empty list for refined read\n",
    "    ori_read_index = 0 # To keep the original read index for insertion point\n",
    "    refined_read_index = 0 # To keep index of insertion point on refined read\n",
    "    refined_read_insert = [] # Make empty list to keep the insertion\n",
    "    refined_read_insert_index_at_ori_read = [] # FROM 0, make empty list to keep index of insertion on original read\n",
    "    refined_read_insert_index_at_refined_read = [] #FROM 0, make empty list to keep index of insertion on refined read\n",
    "    \n",
    "    # From the first cigar, fill the refined read one by one with original read dependent on the cigar\n",
    "    ## If cigar(+), ori-read(-):\n",
    "        ## \"D\", only refined-index move forward\n",
    "        ## \"N\", only refined-index move forward\n",
    "    ## If cigar(+), ori-read(+): \n",
    "        ## \"I\", only ori-index move forward, but save the information of insertion\n",
    "        ## \"S\", only ori-index move forward\n",
    "        ## \"M\", two of the index move forward\n",
    "    for index, cigar in enumerate(cigar_temp_list): \n",
    "        if cigar == \"S\": #Directly ignore it and move the behind forward\n",
    "            ori_read_index += 1 # Move forward on original index\n",
    "            continue\n",
    "        \n",
    "        if cigar == \"H\": #Directly ignore it and move the behind forward\n",
    "            continue\n",
    "            \n",
    "        if cigar == \"I\": #Extract to make a list of inserted element with position and ignore it, moving the behind forward\n",
    "            refined_read_insert.append(read_temp_list[ori_read_index]) # Save the base\n",
    "            refined_read_insert_index_at_ori_read.append(ori_read_index) # Save where it is on original read \n",
    "            refined_read_insert_index_at_refined_read.append(refined_read_index) # Save where it will be on refined read\n",
    "            ori_read_index += 1 # Move forward on original index\n",
    "            continue\n",
    "            \n",
    "        if cigar == \"D\": # Fill \"D\" in refined read\n",
    "            refined_read.append(\"D\") # Fill \"D\"\n",
    "            refined_read_index += 1 # Move forward on refined_read_index\n",
    "            continue\n",
    "            \n",
    "        if cigar == \"N\": # Fill \"N\" in refined read\n",
    "            refined_read.append(\"N\") # Fill \"N\"\n",
    "            refined_read_index += 1 # Move forward on refined_read_index\n",
    "            continue\n",
    "            \n",
    "        if cigar == \"M\": # Fill the base in refined read\n",
    "            refined_read.append(read_temp_list[ori_read_index]) # Fill the base\n",
    "            ori_read_index += 1 # Move forward on original read index\n",
    "            refined_read_index += 1 # Move forward on refined read index\n",
    "            continue\n",
    "            \n",
    "        else:\n",
    "            print(cigar,\"is not defined at\",index) # If there is any exception, print it\n",
    "            \n",
    "    refined_read = \"\".join(refined_read) # Combine list of the base pair \n",
    "    refined_read_insert = np.array(refined_read_insert)\n",
    "    refined_read_insert_index_at_ori_read = np.array(refined_read_insert_index_at_ori_read)\n",
    "    refined_read_insert_index_at_refined_read = np.array(refined_read_insert_index_at_refined_read)\n",
    "    return refined_read, refined_read_insert, refined_read_insert_index_at_ori_read, refined_read_insert_index_at_refined_read\n",
    "\n",
    "\n",
    "def find_insertion_forbackward(index, skip_range, window, read_selected_matrix, to_use_selected_scaffold_df):\n",
    "    '''\n",
    "    To find if there is any insertion in the window of one locus, \n",
    "    and make dataframes of insertion forward and backward respectively\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    index : int\n",
    "        The locus of scaffold.\n",
    "    skip range : int\n",
    "        The range skipped.\n",
    "    window : int\n",
    "        The window of one locus.\n",
    "    read_selected_matrix : numpy array\n",
    "        2D array that includes the information of reads covering one locus\n",
    "    to_use_selected_scaffold_df : pandas.DataFrame\n",
    "        \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    forward_df : pandas.DataFrame\n",
    "        a dataframe saving the information of forward insertion : read, index, base, read order\n",
    "        \n",
    "    backward_df : pandas.DataFrame\n",
    "        a dataframe saving the information of backward insertion : read, index, base, read order\n",
    "    '''\n",
    "    forward_i_read = []\n",
    "    forward_i_index = []\n",
    "    forward_i_base = []\n",
    "    forward_i_read_order = [] # FRPM 0 \n",
    "\n",
    "    backward_i_read = []\n",
    "    backward_i_index = []\n",
    "    backward_i_base = []\n",
    "    backward_i_read_order = [] # FROM 0\n",
    "    \n",
    "    # For every read that covers one locus\n",
    "    for read_order, reads in enumerate(read_selected_matrix[(index - skip_range)]): \n",
    "        \n",
    "        if np.isnan(reads): # Until no read, stop the iteration\n",
    "            break\n",
    "\n",
    "        refined_read_i_index = index - to_use_selected_scaffold_df[\"start\"][reads] # To find the index of the locus on one read\n",
    "        start_insertion_index = refined_read_i_index - ((window - 1) / 2) # To find the start point of one read that would be inside the window\n",
    "        end_insertion_index = refined_read_i_index + ((window - 1) / 2) - 1 # To find the end point of one read that would be inside the window\n",
    "        \n",
    "        # Check every insertion index of one read\n",
    "        for insertion_index in to_use_selected_scaffold_df[\"ori insertion index\"][reads]:\n",
    "            if refined_read_i_index <= insertion_index <= end_insertion_index: # If it is after the middle locus but before the end point\n",
    "                forward_i_read.append(reads) # Add the reads\n",
    "                forward_i_index.append(to_use_selected_scaffold_df[\"start\"][reads] + insertion_index) # Where to insert on original index of scaffold\n",
    "                forward_i_base.append(to_use_selected_scaffold_df[\"read\"][reads][insertion_index]) # Add the base\n",
    "                forward_i_read_order.append(read_order) # Add the read order which means the depth if plus 1 cause the first is ref  \n",
    "\n",
    "            elif start_insertion_index <= insertion_index <= (refined_read_i_index - 1): # If it is before the middle locus but after the end point\n",
    "                backward_i_read.append(reads) # Add the reads\n",
    "                backward_i_index.append(to_use_selected_scaffold_df[\"start\"][reads] + insertion_index) # Where to insert on original index of scaffold\n",
    "                backward_i_base.append(to_use_selected_scaffold_df[\"read\"][reads][insertion_index]) # Add the base\n",
    "                backward_i_read_order.append(read_order) # Add the read order which means the depth if plus 1 cause the first is ref  \n",
    "                \n",
    "    forward_df = pd.DataFrame({\"read\": forward_i_read, \"index\": forward_i_index, \"base\":forward_i_base, \"read order\":forward_i_read_order}) # Make the dataframe\n",
    "    backward_df = pd.DataFrame({\"read\": backward_i_read, \"index\": backward_i_index, \"base\":backward_i_base, \"read order\":backward_i_read_order}) # Make the dataframe\n",
    "    \n",
    "    return forward_df, backward_df\n",
    "\n",
    "\n",
    "def insertion_fill_in(index, depth, window, pre_image_char_part, forward_df, backward_df):\n",
    "    '''\n",
    "    If there is any insertion in the window of one locus,\n",
    "    insert it and move the other bases forward and backward \n",
    "    than delete the exceed\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    index : int\n",
    "        The locus of scaffold.\n",
    "    depth : int\n",
    "        The depth.\n",
    "    window : int\n",
    "        The window of one locus.\n",
    "    pre_image_char_part : 2D numpy array\n",
    "        The 2D array of one locus: pre_image_char_part = pre_image_char[(index - skip_range),:,:]\n",
    "    forward_df : pandas.DataFrame\n",
    "        The forward dataframe generated by find_insertion_forbackward function\n",
    "    backward_df : pandas.DataFrame\n",
    "        The backward dataframe generated by find_insertion_forbackward function\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pre_image_char_part_output : 2D numpy array\n",
    "        a new 2D array of one locus to replace the original one\n",
    "    '''\n",
    "    # To sort the forward dataframe, ascending order(1->2->3...)\n",
    "    forward_df = forward_df.sort_values(by = \"index\", ascending = True)\n",
    "    \n",
    "    # To extract read order, index, base from forward dataframe\n",
    "    for for_read_order, for_index, for_base in zip(forward_df[\"read order\"], forward_df[\"index\"], forward_df[\"base\"]):\n",
    "        insertion_location = int(for_index - index + ((window - 1) / 2)) # To find the insertion location in the window\n",
    "        insertion_array = np.chararray(depth, unicode = True) # Make a empty array to insert\n",
    "        insertion_array[for_read_order + 1] = for_base # Add the insertion base to the empty array\n",
    "        pre_image_char_part = np.insert(pre_image_char_part, insertion_location, insertion_array, 1) # Insert it\n",
    "    \n",
    "    # To sort the backward dataframe, descending order(3->2->1...)\n",
    "    backward_df = backward_df.sort_values(by = \"index\", ascending = False)\n",
    "    \n",
    "    # To count how many insertion backward for final cutting of the matrix\n",
    "    cut_length = len(backward_df)\n",
    "    \n",
    "    # To extract read order, index, base from backward dataframe\n",
    "    for back_read_order, back_index, back_base in zip(backward_df[\"read order\"], backward_df[\"index\"], backward_df[\"base\"]):\n",
    "        insertion_location = int(back_index - index + ((window - 1) / 2)) # To find the insertion location in the window\n",
    "        insertion_array = np.chararray(depth, unicode = True) # Make a empty array to insert\n",
    "        insertion_array[back_read_order + 1] = back_base # Add the insertion base to the empty array\n",
    "        pre_image_char_part = np.insert(pre_image_char_part, insertion_location, insertion_array, 1) # Insert it\n",
    "\n",
    "    # Cut the required part: if 2 backward insertion and 3 forward insertion with window, extract 2 : 2+window-1    \n",
    "    pre_image_char_part_output = pre_image_char_part[:,(cut_length):(cut_length + window)]\n",
    "    \n",
    "    return pre_image_char_part_output\n",
    "\n",
    "'''\n",
    "Read fasta file\n",
    "'''\n",
    "def read_fasta(fasta):\n",
    "    fasta_sequences = SeqIO.parse(open(fasta),\"fasta\")\n",
    "    fasta_name = []\n",
    "    fasta_sequence = []\n",
    "    for fasta in fasta_sequences:\n",
    "        name, sequence = fasta.id, str(fasta.seq)\n",
    "        fasta_name.append(name)\n",
    "        fasta_sequence.append(sequence)\n",
    "    fasta_dict = {\"scaffold\":fasta_name,\"sequence\":fasta_sequence}\n",
    "    fasta_df = pd.DataFrame(fasta_dict)\n",
    "    fasta_df[\"len\"] = fasta_df[\"sequence\"].str.len()\n",
    "    return fasta_df\n",
    "\n",
    "'''\n",
    "Read sam file\n",
    "'''\n",
    "def read_sam(samfile):\n",
    "    # Read sam file\n",
    "    sam=[]\n",
    "    with open(samfile, \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            sam.append(line.split(\"\\t\"))\n",
    "    sam = np.array(sam)\n",
    "    return sam\n",
    "\n",
    "'''\n",
    "Read bed file\n",
    "'''\n",
    "def read_bed(bedfile):\n",
    "    # Read bed file\n",
    "    bed=[]\n",
    "    with open(bedfile, \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            bed.append(line.split(\"\\t\"))\n",
    "    bed = np.array(bed)\n",
    "    return bed\n",
    "\n",
    "'''\n",
    "Scaffold fliter\n",
    "'''\n",
    "def scaffold_min_and_max(fasta_df):\n",
    "    minimum = int(input(\"Minimum: \"))\n",
    "    maximum = int(input(\"Maximum: \"))\n",
    "    mask_min = (fasta_df[\"len\"] >= minimum)\n",
    "    mask_max = (fasta_df[\"len\"] <= maximum)\n",
    "    fasta_df_fliter = fasta_df[(mask_min & mask_max)]\n",
    "    if len(fasta_df_fliter) == 0:\n",
    "        print(\"There is no scaffold match this length interval\")\n",
    "        return scaffold_min_and_max(fasta_df)\n",
    "    else:\n",
    "        print(\"Number of scaffold: \" + str(len(fasta_df_fliter)))\n",
    "        print(\"There is/are:\")\n",
    "        print(fasta_df_fliter[\"scaffold\"])\n",
    "        return fasta_df_fliter, minimum, maximum\n",
    "    \n",
    "'''\n",
    "For each scaffold, find coveraging read in the sam\n",
    "'''\n",
    "def find_read_based_on_scaffold(scaffold_name, sam):\n",
    "    # Find index of selected scaffold in bam\n",
    "    scaffold_in_sam = list([i for i,item in enumerate(sam) if scaffold_name in item])\n",
    "\n",
    "    # Make a DataFrame for selected scaffold information\n",
    "\n",
    "    selected_scaffold_df = [sam[i] for i in scaffold_in_sam]\n",
    "    selected_scaffold_df = pd.DataFrame(selected_scaffold_df)\n",
    "    return selected_scaffold_df\n",
    "\n",
    "'''\n",
    "Select useful information in dafaframe of selected scaffold\n",
    "'''\n",
    "def make_read_scaffold_df(fasta_df, selected_scaffold_df, scaffold_name, expand = 0):\n",
    "    scaffold_length = fasta_df[fasta_df[\"scaffold\"] == scaffold_name][\"len\"].values[0]\n",
    "    \n",
    "    pd.options.mode.chained_assignment = None\n",
    "    to_use_selected_scaffold_df_pre = selected_scaffold_df[[1,2,3,4,5,9]]\n",
    "    to_use_selected_scaffold_df = to_use_selected_scaffold_df_pre[to_use_selected_scaffold_df_pre[9] != \"*\"]\n",
    "    if len(to_use_selected_scaffold_df) == 0:\n",
    "        return to_use_selected_scaffold_df\n",
    "    to_use_selected_scaffold_df.columns = [\"flag\",\"scaffold\",\"start\",\"mapping quality\",\"cigar\",\"read\"]\n",
    "    to_use_selected_scaffold_df[\"read length\"] = to_use_selected_scaffold_df[\"read\"].str.len()\n",
    "    to_use_selected_scaffold_df[\"start\"] = to_use_selected_scaffold_df[\"start\"].astype('int64')\n",
    "    to_use_selected_scaffold_df[\"mapping quality\"] = to_use_selected_scaffold_df[\"mapping quality\"].astype('int64')\n",
    "    to_use_selected_scaffold_df[\"flag\"] = to_use_selected_scaffold_df[\"flag\"].astype('int64')\n",
    "    to_use_selected_scaffold_df[\"end\"] = (to_use_selected_scaffold_df[\"start\"] + to_use_selected_scaffold_df[\"read length\"] - 1)\n",
    "    to_use_selected_scaffold_df[\"refined_by_cigar\"] = to_use_selected_scaffold_df.apply(lambda x: refine_read_by_cigar(x[\"read\"], x[\"cigar\"]), axis=1)\n",
    "    to_use_selected_scaffold_df[[\"refined read\", \n",
    "                                 \"insertion\",\n",
    "                                 \"ori insertion index\",\n",
    "                                 \"re insertion index\"]] = pd.DataFrame(to_use_selected_scaffold_df[\"refined_by_cigar\"].tolist(), index=to_use_selected_scaffold_df.index)\n",
    "    to_use_selected_scaffold_df.drop(columns=[\"refined_by_cigar\"],inplace=True)\n",
    "    to_use_selected_scaffold_df[\"refined read length\"] = to_use_selected_scaffold_df[\"refined read\"].str.len()\n",
    "    to_use_selected_scaffold_df[\"refined end\"] = (to_use_selected_scaffold_df[\"start\"] + to_use_selected_scaffold_df[\"refined read length\"] - 1)\n",
    "    to_use_selected_scaffold_df[\"expand start\"] = (to_use_selected_scaffold_df[\"start\"] - expand)\n",
    "    to_use_selected_scaffold_df.loc[to_use_selected_scaffold_df[\"expand start\"] < 1, \"expand start\"] = 1\n",
    "    to_use_selected_scaffold_df[\"expand end\"] = (to_use_selected_scaffold_df[\"refined end\"] + expand)\n",
    "    to_use_selected_scaffold_df.loc[to_use_selected_scaffold_df[\"expand end\"] > scaffold_length, \"expand end\"] = scaffold_length\n",
    "    \n",
    "    return to_use_selected_scaffold_df\n",
    "\n",
    "'''\n",
    "Make a matrix of reads which meet the criteria of each locus\n",
    "'''\n",
    "def make_read_selected_matrix_find_reads(to_use_selected_scaffold_df, ALL_TOUCH_INCLUDED, window, depth, ONLY_FILL_THE_LONGEST, index):\n",
    "    mask1 = to_use_selected_scaffold_df[\"start\"] <= index + ALL_TOUCH_INCLUDED * ((window + 1) / 2)\n",
    "    mask2 = to_use_selected_scaffold_df[\"refined end\"] >= index + ALL_TOUCH_INCLUDED * ((window + 1) / 2)\n",
    "    scaffold_df_selected_by_mask = to_use_selected_scaffold_df[(mask1 & mask2)]\n",
    "    read_selected_array = np.empty(depth)\n",
    "    read_selected_array[:] = np.nan\n",
    "    if ONLY_FILL_THE_LONGEST == True:\n",
    "        if len(scaffold_df_selected_by_mask[\"read length\"]) != 0:\n",
    "            max_length_read = scaffold_df_selected_by_mask[\"read length\"].idxmax()\n",
    "            read_start = to_use_selected_scaffold_df[\"start\"][max_length_read]\n",
    "            \n",
    "            if to_use_selected_scaffold_df[\"refined read\"][max_length_read][(index - read_start)] == \"N\" or to_use_selected_scaffold_df[\"refined read\"][max_length_read][(index - read_start)] == \"N\":\n",
    "                full_read_array = scaffold_df_selected_by_mask.index[0]\n",
    "                if type(full_read_array) is np.int64:\n",
    "                    read_selected_array[0:1] = scaffold_df_selected_by_mask[\"read length\"].idxmax()\n",
    "                elif len(full_read_array) >= 2:\n",
    "                    print(\"yes\")\n",
    "                    full_read_array_element = []\n",
    "                    for reads in full_read_array:\n",
    "                        full_read_array_element.append(to_use_selected_scaffold_df[\"refined read\"][reads][(index - read_start)])\n",
    "                    full_read_array_element = np.array(full_read_array_element)\n",
    "                    if len(full_read_array[(full_read_array_element != \"N\") & (full_read_array_element != \"D\")]) != 0:\n",
    "                        read_selected_array[0:1] = to_use_selected_scaffold_df.iloc[full_read_array[full_read_array_element != \"N\"]][\"read length\"].idxmax()\n",
    "                    else:\n",
    "                        read_selected_array[0:1] = scaffold_df_selected_by_mask[\"read length\"].idxmax()\n",
    "                else:\n",
    "                    read_selected_array[0:1] = scaffold_df_selected_by_mask[\"read length\"].idxmax()\n",
    "            else:\n",
    "                read_selected_array[0:1] = scaffold_df_selected_by_mask[\"read length\"].idxmax()\n",
    "        \n",
    "    else:\n",
    "        length = len(to_use_selected_scaffold_df[(mask1 & mask2)].index)\n",
    "        read_selected_array[0:length] = to_use_selected_scaffold_df[(mask1 & mask2)].index\n",
    "    \n",
    "    return read_selected_array\n",
    "\n",
    "def make_read_selected_matrix(scaffold_name, searching_interval, to_use_selected_scaffold_df, ALL_TOUCH_INCLUDED, window, skip_range, depth, ONLY_FILL_THE_LONGEST, core):\n",
    "    \n",
    "    # Interval for searching\n",
    "    searching_interval_length = len(searching_interval)\n",
    "\n",
    "    # Search every base that are in this interval\n",
    "    # And select feasible reads for each base on locus of genome\n",
    "    if __name__ == \"__main__\" :  \n",
    "        \n",
    "        pool = Pool(core) # Pool() \n",
    "        func = partial(make_read_selected_matrix_find_reads, to_use_selected_scaffold_df, ALL_TOUCH_INCLUDED, window, depth, ONLY_FILL_THE_LONGEST)\n",
    "        read_selected_matrix = pool.map(func, searching_interval) \n",
    "        pool.close()  \n",
    "        pool.join()   \n",
    "    \n",
    "    read_selected_matrix = np.array(read_selected_matrix)\n",
    "        \n",
    "    return read_selected_matrix\n",
    "\n",
    "'''\n",
    "Make a 4 dimension matrix of pre-image base \n",
    "'''\n",
    "def image_pileup_Parallelism(scaffold_name, fasta_df, to_use_selected_scaffold_df, read_selected_matrix, depth, window, skip_range, on_positive_strand_not_provide, index, INSERTION = False, REVERSE_FOR_NEG = True):\n",
    "    # To search the base based on index\n",
    "    # From index=0~the last one, means from the first one to the last\n",
    "    pre_pre_image_char_matrix = np.chararray((depth, window), unicode = True)\n",
    "    # FIRST!!! FILL ref at depth=0\n",
    "    # From start point \"0\" to end point \"window - 1\" \n",
    "    middle = ((window - 1) / 2) # Index not order\n",
    "    scaffold_max_length = fasta_df[fasta_df[\"scaffold\"] == scaffold_name][\"len\"].values[0]\n",
    "\n",
    "    # at \"0\" fill: (index - middle)\n",
    "    # at \"coverage interval - 1\" fill: (index + middle) \n",
    "    # This is index of what to fill\n",
    "    fasta_fill_index_start = (index - middle) # Order not index\n",
    "    fasta_fill_index_end = (index + middle) # Order not index\n",
    "\n",
    "    # Set all the element to \"N\" first\n",
    "    pre_pre_image_char_matrix[0, :] = \"N\"\n",
    "    base_fill_index_start = 0\n",
    "    base_fill_index_end = window\n",
    "    if fasta_fill_index_start < 1:\n",
    "        base_fill_index_start = int(np.abs(fasta_fill_index_start - 1))\n",
    "        fasta_fill_index_start = 1\n",
    "\n",
    "    elif fasta_fill_index_end > scaffold_max_length:\n",
    "        base_fill_index_end = int((scaffold_max_length - fasta_fill_index_end))\n",
    "        fasta_fill_index_end = scaffold_max_length\n",
    "    \n",
    "    pre_pre_image_char_matrix[0, base_fill_index_start:base_fill_index_end] = np.array(list(fasta_df[fasta_df[\"scaffold\"]==scaffold_name][\"sequence\"].values[0][int(fasta_fill_index_start - 1):int(fasta_fill_index_end)]))   \n",
    "    \n",
    "    for i, reads in enumerate(read_selected_matrix[(index - skip_range)]):\n",
    "        # If there is no read or until the end of the coverage, jump to the next locus\n",
    "        if np.isnan(reads):\n",
    "            break\n",
    "\n",
    "        else:\n",
    "            read_start = to_use_selected_scaffold_df[\"start\"][reads] # To find the start point of the read\n",
    "            read_end = to_use_selected_scaffold_df[\"refined end\"][reads] # To find the end point of the read\n",
    "\n",
    "            pre_pre_image_char_matrix[(i+1), :] = \"N\"\n",
    "            image_read_fill_start = 0\n",
    "            image_read_fill_end = int(window)\n",
    "            read_fill_start = int(fasta_fill_index_start - read_start)\n",
    "            read_fill_end = int(fasta_fill_index_end - read_start) + 1\n",
    "\n",
    "            if read_start > fasta_fill_index_start:\n",
    "                image_read_fill_start = int(read_start - fasta_fill_index_start)\n",
    "                pre_pre_image_char_matrix[(i+1), image_read_fill_start:image_read_fill_end] = np.array(list(to_use_selected_scaffold_df[\"refined read\"][reads][:read_fill_end]))\n",
    "\n",
    "            elif read_end < fasta_fill_index_end:\n",
    "                image_read_fill_end = int(read_end - fasta_fill_index_end)\n",
    "                pre_pre_image_char_matrix[(i+1), image_read_fill_start:image_read_fill_end] = np.array(list(to_use_selected_scaffold_df[\"refined read\"][reads][read_fill_start:]))\n",
    "\n",
    "            else:    \n",
    "                pre_pre_image_char_matrix[(i+1), image_read_fill_start:image_read_fill_end] = np.array(list(to_use_selected_scaffold_df[\"refined read\"][reads][read_fill_start:read_fill_end]))\n",
    "    \n",
    "    ##################### DEAL WITH N #######################################\\\n",
    "    for i in np.arange(0, pre_pre_image_char_matrix.shape[1]): # For all the element in the window\n",
    "        if pre_pre_image_char_matrix[0, i] == \"N\": # Check the top element is \"N\" or not\n",
    "            A = np.count_nonzero(pre_pre_image_char_matrix[:, i] == \"A\") # Count \"A\" \n",
    "            T = np.count_nonzero(pre_pre_image_char_matrix[:, i] == \"T\") # Count \"T\"\n",
    "            C = np.count_nonzero(pre_pre_image_char_matrix[:, i] == \"C\") # Count \"C\"\n",
    "            G = np.count_nonzero(pre_pre_image_char_matrix[:, i] == \"G\") # Count \"G\"\n",
    "            N = np.count_nonzero(pre_pre_image_char_matrix[:, i] == \"N\") # Count \"N\"\n",
    "\n",
    "            base_count_list = np.array([A, T, C, G, N]) # Make a list of base\n",
    "            base_unique_list = np.array([\"A\", \"T\", \"C\", \"G\", \"N\"]) # Make a list of index of the base\n",
    "            base_count_list_sort = np.sort(base_count_list) # Sort the list of base\n",
    "            if base_count_list_sort[-1] != base_count_list_sort[-2]: # To check if there any duplicated most frequent elements\n",
    "                pre_pre_image_char_matrix[0, i] == base_unique_list[base_count_list.argmax()] # If no, fill the most frequent one\n",
    "    \n",
    "    ####################################### INSERTION #######################################\n",
    "    if INSERTION == True:\n",
    "        forward_df, backward_df = find_insertion_forbackward(index, skip_range, window, read_selected_matrix, to_use_selected_scaffold_df)\n",
    "        if (len(forward_df) != 0) or  (len(backward_df) != 0): # If there is any insertion, use pre_image_char function\n",
    "            pre_pre_image_char_matrix = insertion_fill_in(index, depth, window, pre_pre_image_char_matrix, forward_df, backward_df)\n",
    "            \n",
    "    ####################################### REVERSE STRAND IF ON NEGATIVE STRAND #######################################\n",
    "    if REVERSE_FOR_NEG == True:\n",
    "        if pre_pre_image_char_matrix.shape[0] == 2:\n",
    "            reads = read_selected_matrix[(index - skip_range)][0]\n",
    "            if not np.isnan(reads):\n",
    "                positive_flag = to_use_selected_scaffold_df[\"flag\"][reads]\n",
    "                binary_flag = np.binary_repr(positive_flag)\n",
    "                if (len(binary_flag) >= 5) and (list(binary_flag)[-5] == \"1\"):\n",
    "                    pre_pre_image_char_matrix = np.flip(pre_pre_image_char_matrix, axis = 1)\n",
    "                    reverse_temp = pre_pre_image_char_matrix\n",
    "                    reverse_temp[pre_pre_image_char_matrix == \"A\"] = \"T\"\n",
    "                    reverse_temp[pre_pre_image_char_matrix == \"T\"] = \"A\"\n",
    "                    reverse_temp[pre_pre_image_char_matrix == \"C\"] = \"G\"\n",
    "                    reverse_temp[pre_pre_image_char_matrix == \"G\"] = \"C\"\n",
    "                    pre_pre_image_char_matrix = reverse_temp\n",
    "        else:\n",
    "            print(\"REVERSE_FOR_NEG is only for depth=2\")\n",
    "    \n",
    "    ####################################### COLOR\n",
    "    pre_image_base_color = base_to_color_full_array_input(pre_pre_image_char_matrix) \n",
    "    \n",
    "    ####################################### MAPPING QUALITY\n",
    "    pre_image_mapping_quality_temp = np.full(pre_pre_image_char_matrix.shape, mapping_set_empty)\n",
    "    \n",
    "    for i, reads in enumerate(read_selected_matrix[(index - skip_range)]):\n",
    "        # If there is no read or until the end of the coverage, jump to the next locus\n",
    "        if np.isnan(reads):\n",
    "            break\n",
    "        else:\n",
    "            mapping_quality = to_use_selected_scaffold_df[\"mapping quality\"][reads]\n",
    "            pre_image_mapping_quality_temp[(i + 1), :] = mapping_quality_fill(pre_pre_image_char_matrix[(i+1), :], mapping_quality)\n",
    "    ####################################### ON POSITIVE STRAND\n",
    "    #on_positive_strand_temp = np.full(pre_pre_image_char_matrix.shape, on_positive_strand_not_provide)\n",
    "    #\n",
    "    #for i, reads in enumerate(read_selected_matrix[(index - skip_range)]):\n",
    "    #    # If there is no read or until the end of the coverage, jump to the next locus\n",
    "    #    if np.isnan(reads):\n",
    "    #        break\n",
    "    #    else:\n",
    "    #        positive_flag = to_use_selected_scaffold_df[\"flag\"][reads]\n",
    "    #        on_positive_strand_temp[(i + 1), :] = on_positive_strand_fill(pre_pre_image_char_matrix[(i+1), :], positive_flag)\n",
    "    ####################################### MATCH REF\n",
    "    #pre_image_match_ref_temp = match_ref_fill(depth, window, pre_pre_image_char_matrix)\n",
    "    \n",
    "    return pre_image_base_color, pre_image_mapping_quality_temp\n",
    "\n",
    "\n",
    "def image_pileup(scaffold_name, \n",
    "                 fasta_df, \n",
    "                 read_selected_matrix, \n",
    "                 to_use_selected_scaffold_df, \n",
    "                 window, \n",
    "                 depth, \n",
    "                 skip_range,\n",
    "                 searching_interval, \n",
    "                 pixel_max, \n",
    "                 bias_of_read, \n",
    "                 mapping_quality_not_provide, \n",
    "                 on_positive_strand_not_provide, \n",
    "                 not_match_ref, core):\n",
    "    \n",
    "    # 3 dimention maxtrix initialization: base(char), base color(int), base quality(char), on postive strand(int)\n",
    "    ## x: searching_interval \n",
    "    ## y: depth\n",
    "    ## z: coverage read interval\n",
    "    ####coverage_interval = (length_of_read * 2 -1 + bias_of_read) \n",
    "    #window = 149\n",
    "    searching_interval_length = len(searching_interval)\n",
    "\n",
    "    scaffold_max_length = fasta_df[fasta_df[\"scaffold\"] == scaffold_name][\"len\"].values[0]\n",
    "    middle = ((window - 1) / 2) # Index not order\n",
    "    \n",
    "    # FIRST!!! FILL REF\n",
    "    # SECOND!!! FILL read at depth=1~\n",
    "    if __name__ == \"__main__\" :  \n",
    "        pre_image_base_color = []\n",
    "        pre_image_mapping_quality = []\n",
    "        pre_image_on_positive_strand = []\n",
    "        pre_image_match_ref = []\n",
    "        \n",
    "        \n",
    "        \n",
    "        pool = Pool(core) # Pool() \n",
    "        func = partial(image_pileup_Parallelism, scaffold_name, fasta_df, to_use_selected_scaffold_df, read_selected_matrix, depth, window, skip_range, on_positive_strand_not_provide)\n",
    "        for pre_image_base_color_locus, pre_image_mapping_quality_locus in pool.map(func, searching_interval, chunksize=1000): \n",
    "            pre_image_base_color.append(pre_image_base_color_locus)\n",
    "            pre_image_mapping_quality.append(pre_image_mapping_quality_locus)\n",
    "            \n",
    "        pool.close()  \n",
    "        pool.join()  \n",
    "        \n",
    "    #pre_image_char = np.array(pre_image_char)\n",
    "    pre_image_base_color = np.array(pre_image_base_color)\n",
    "    pre_image_mapping_quality = np.array(pre_image_mapping_quality)\n",
    "    \n",
    " \n",
    "    return pre_image_base_color, pre_image_mapping_quality\n",
    "def consider_read_of_one_scaffold_by_bed_region(fasta_df, sam, bed_name, scaffold_name, core, window, depth, expand, output, ALL_TOUCH_INCLUDED = 0, ONLY_FILL_THE_LONGEST=True):\n",
    "    bed = read_bed(bed_name)\n",
    "    bed_df = pd.DataFrame(bed)\n",
    "    bed_df = bed_df[[0,1,2,3]]\n",
    "    bed_df.columns = [\"scaffold\",\"start\",\"end\",\"label\"]\n",
    "    \n",
    "    if scaffold_name != \"all_scaffold\":\n",
    "        \n",
    "        bed_selected_df = bed_df[bed_df[\"scaffold\"]==scaffold_name]\n",
    "        if len(bed_selected_df) == 0:\n",
    "            print(\"There is no scaffold named: \",scaffold_name)\n",
    "            print(\"Please choose the scaffold below:\")\n",
    "            print(bed_df[\"scaffold\"].unique())\n",
    "            sys.exit(\"ERROR! known scaffold name\")\n",
    "        \n",
    "        total_process = len(bed_selected_df)\n",
    "        right_process = 1\n",
    "\n",
    "        start_time = datetime.now()\n",
    "        scaffold_image_dict = {}\n",
    "        scaffold_length = fasta_df[fasta_df[\"scaffold\"] == scaffold_name][\"len\"].values[0]\n",
    "\n",
    "        # Select useful information in dafaframe of selected scaffold\n",
    "        selected_scaffold_df = find_read_based_on_scaffold(scaffold_name, sam)\n",
    "\n",
    "        if len(selected_scaffold_df) == 0:\n",
    "            print(\"no covered reads\")\n",
    "            print(\"==========================================\")\n",
    "            sys.exit(\"ERROR! no covered reads\")\n",
    "            \n",
    "\n",
    "        to_use_selected_scaffold_df = make_read_scaffold_df(fasta_df, selected_scaffold_df, scaffold_name, expand)\n",
    "        if len(to_use_selected_scaffold_df) == 0:\n",
    "            print(\"no covered reads\")\n",
    "            print(\"==========================================\")\n",
    "            sys.exit(\"ERROR! no covered reads\")\n",
    "        to_use_selected_scaffold_df = to_use_selected_scaffold_df.sort_values(by=[\"start\"]) # Sort the reads by start locus\n",
    "\n",
    "\n",
    "        for bed_index in bed_selected_df.index:\n",
    "            start = int(bed_df.iloc[bed_index][\"start\"])\n",
    "            end = int(bed_df.iloc[bed_index][\"end\"])\n",
    "            label = bed_df.iloc[bed_index][\"label\"]\n",
    "            ######\n",
    "            fragment = np.arange((start+1),(end+1))\n",
    "\n",
    "            searching_interval = fragment\n",
    "            skip_range = fragment[0] #Customerization # MUST START FROM 1\n",
    "            start_time_fragment = datetime.now()\n",
    "\n",
    "            store_name = scaffold_name + \"|\" + str(fragment[0]) + \" to \" + str(fragment[-1]) + \"|\"+label\n",
    "            print(\"Start process \",right_process,\" / \",total_process,\" : \",store_name)\n",
    "            print(\"Step 1: finding reads\", end='')\n",
    "            start_time_temp = datetime.now()\n",
    "            read_selected_matrix = make_read_selected_matrix(scaffold_name, \n",
    "                                                             searching_interval, \n",
    "                                                             to_use_selected_scaffold_df, \n",
    "                                                             ALL_TOUCH_INCLUDED,\n",
    "                                                             window, skip_range, \n",
    "                                                             depth, ONLY_FILL_THE_LONGEST, core)\n",
    "            end_time_temp  = datetime.now()\n",
    "            print(\" | Duration: {}\".format(end_time_temp - start_time_temp))\n",
    "\n",
    "\n",
    "            # Make a 3 dimension image\n",
    "            pixel_max = 254  #Customerization\n",
    "            bias_of_read = 0 #Customerization\n",
    "            mapping_quality_not_provide = 255 #Customerization\n",
    "            on_positive_strand_not_provide = 255 #Customerization\n",
    "            not_match_ref = pixel_max * 1 #Customerization\n",
    "\n",
    "            print(\"Step 2: image pileup\", end='')\n",
    "            start_time_temp = datetime.now()\n",
    "            pre_image_base_color, pre_image_mapping_quality = image_pileup(scaffold_name,\n",
    "                                     fasta_df, \n",
    "                                     read_selected_matrix, \n",
    "                                     to_use_selected_scaffold_df, \n",
    "                                     window, \n",
    "                                     depth,\n",
    "                                     skip_range,\n",
    "                                     searching_interval, \n",
    "                                     pixel_max, \n",
    "                                     bias_of_read, \n",
    "                                     mapping_quality_not_provide, \n",
    "                                     on_positive_strand_not_provide, \n",
    "                                     not_match_ref, core)\n",
    "            end_time_temp  = datetime.now()\n",
    "            print(\" | Duration: {}\".format(end_time_temp - start_time_temp))\n",
    "\n",
    "            print(\"Step 3: combination\", end='')\n",
    "            start_time_temp = datetime.now()\n",
    "            FINAL_RGB = channels_to_RGB(pixel_max_empty_def,\n",
    "                                    pre_image_base_color, \n",
    "                                    pre_image_mapping_quality)\n",
    "            end_time_temp  = datetime.now()\n",
    "            print(\" | Duration: {}\".format(end_time_temp - start_time_temp))\n",
    "\n",
    "            # Save to dictionary\n",
    "            print(\"Step 4: save to dictionary\", end='')\n",
    "\n",
    "\n",
    "            start_time_temp = datetime.now()\n",
    "            scaffold_image_dict[store_name] = FINAL_RGB\n",
    "            end_time_temp  = datetime.now()\n",
    "            print(\" | Duration: {}\".format(end_time_temp - start_time_temp))\n",
    "\n",
    "\n",
    "            end_time_fragment = datetime.now()\n",
    "            right_process += 1\n",
    "\n",
    "            print(\"finish \",store_name, end='')\n",
    "            print(\" | Duration: {}\".format(end_time_fragment - start_time_fragment))\n",
    "            print(\"==========================================\")\n",
    "\n",
    "\n",
    "            print(\"==================================================================================\")\n",
    "\n",
    "        print(\"Final stage: save to pickle\")\n",
    "        # Store data to pickle(serialize)\n",
    "\n",
    "        with open(output, \"wb\") as handle:\n",
    "            pickle.dump(scaffold_image_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        end_time = datetime.now()\n",
    "        print(\"Total duration: {}\".format(end_time - start_time))\n",
    "    \n",
    "    else:\n",
    "        total_process = len(bed_df)\n",
    "        right_process = 1\n",
    "        for scaffold_name in bed_df[\"scaffold\"].unique():\n",
    "            bed_selected_df = bed_df[bed_df[\"scaffold\"]==scaffold_name]\n",
    "\n",
    "            start_time = datetime.now()\n",
    "            scaffold_image_dict = {}\n",
    "            scaffold_length = fasta_df[fasta_df[\"scaffold\"] == scaffold_name][\"len\"].values[0]\n",
    "\n",
    "            # Select useful information in dafaframe of selected scaffold\n",
    "            selected_scaffold_df = find_read_based_on_scaffold(scaffold_name, sam)\n",
    "\n",
    "            if len(selected_scaffold_df) == 0:\n",
    "                print(\"no covered reads\")\n",
    "                print(\"==========================================\")\n",
    "                continue\n",
    "            to_use_selected_scaffold_df = make_read_scaffold_df(fasta_df, selected_scaffold_df, scaffold_name, expand)\n",
    "            if len(to_use_selected_scaffold_df) == 0:\n",
    "                print(\"no covered reads\")\n",
    "                print(\"==========================================\")\n",
    "                continue\n",
    "            to_use_selected_scaffold_df = to_use_selected_scaffold_df.sort_values(by=[\"start\"]) # Sort the reads by start locus\n",
    "\n",
    "\n",
    "            for bed_index in bed_selected_df.index:\n",
    "                start = int(bed_df.iloc[bed_index][\"start\"])\n",
    "                end = int(bed_df.iloc[bed_index][\"end\"])\n",
    "                label = bed_df.iloc[bed_index][\"label\"]\n",
    "                ######\n",
    "                fragment = np.arange(start,(end+1))\n",
    "\n",
    "                searching_interval = fragment\n",
    "                skip_range = fragment[0] #Customerization # MUST START FROM 1\n",
    "                start_time_fragment = datetime.now()\n",
    "\n",
    "                store_name = scaffold_name + \"|\" + str(fragment[0]) + \" to \" + str(fragment[-1]) + \"|\"+label\n",
    "                print(\"Start process \",right_process,\" / \",total_process,\" : \",store_name)\n",
    "                print(\"Step 1: finding reads\", end='')\n",
    "                start_time_temp = datetime.now()\n",
    "                read_selected_matrix = make_read_selected_matrix(scaffold_name, \n",
    "                                                                 searching_interval, \n",
    "                                                                 to_use_selected_scaffold_df, \n",
    "                                                                 ALL_TOUCH_INCLUDED,\n",
    "                                                                 window, skip_range, \n",
    "                                                                 depth, ONLY_FILL_THE_LONGEST, core)\n",
    "                end_time_temp  = datetime.now()\n",
    "                print(\" | Duration: {}\".format(end_time_temp - start_time_temp))\n",
    "\n",
    "\n",
    "                # Make a 3 dimension image\n",
    "                pixel_max = 254  #Customerization\n",
    "                bias_of_read = 0 #Customerization\n",
    "                mapping_quality_not_provide = 255 #Customerization\n",
    "                on_positive_strand_not_provide = 255 #Customerization\n",
    "                not_match_ref = pixel_max * 1 #Customerization\n",
    "\n",
    "                print(\"Step 2: image pileup\", end='')\n",
    "                start_time_temp = datetime.now()\n",
    "                pre_image_base_color, pre_image_mapping_quality = image_pileup(scaffold_name,\n",
    "                                         fasta_df, \n",
    "                                         read_selected_matrix, \n",
    "                                         to_use_selected_scaffold_df, \n",
    "                                         window, \n",
    "                                         depth,\n",
    "                                         skip_range,\n",
    "                                         searching_interval, \n",
    "                                         pixel_max, \n",
    "                                         bias_of_read, \n",
    "                                         mapping_quality_not_provide, \n",
    "                                         on_positive_strand_not_provide, \n",
    "                                         not_match_ref, core)\n",
    "                end_time_temp  = datetime.now()\n",
    "                print(\" | Duration: {}\".format(end_time_temp - start_time_temp))\n",
    "\n",
    "                print(\"Step 3: combination\", end='')\n",
    "                start_time_temp = datetime.now()\n",
    "                FINAL_RGB = channels_to_RGB(pixel_max_empty_def,\n",
    "                                        pre_image_base_color, \n",
    "                                        pre_image_mapping_quality)\n",
    "                end_time_temp  = datetime.now()\n",
    "                print(\" | Duration: {}\".format(end_time_temp - start_time_temp))\n",
    "\n",
    "                # Save to dictionary\n",
    "                print(\"Step 4: save to dictionary\", end='')\n",
    "\n",
    "\n",
    "                start_time_temp = datetime.now()\n",
    "                scaffold_image_dict[store_name] = FINAL_RGB\n",
    "                end_time_temp  = datetime.now()\n",
    "                print(\" | Duration: {}\".format(end_time_temp - start_time_temp))\n",
    "\n",
    "\n",
    "                end_time_fragment = datetime.now()\n",
    "                right_process += 1\n",
    "\n",
    "                print(\"finish \",store_name, end='')\n",
    "                print(\" | Duration: {}\".format(end_time_fragment - start_time_fragment))\n",
    "                print(\"==========================================\")\n",
    "\n",
    "\n",
    "            print(\"==================================================================================\")\n",
    "\n",
    "        print(\"Final stage: save to pickle\")\n",
    "        # Store data to pickle(serialize)\n",
    "\n",
    "        with open(output, \"wb\") as handle:\n",
    "            pickle.dump(scaffold_image_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        end_time = datetime.now()\n",
    "        print(\"Total duration: {}\".format(end_time - start_time))\n",
    "        \n",
    "#### MAIN ######\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"-if\", \"--inputfasta\", type=str, help=\"the input fasta file\")\n",
    "parser.add_argument(\"-is\", \"--inputsam\", type=str, help=\"the input sam file\")\n",
    "parser.add_argument(\"-ib\", \"--inputbed\", type=str, help=\"the input bed file\")\n",
    "parser.add_argument(\"-o\", \"--output\",type=str, help=\"the output image file name, must end with .pickle\")\n",
    "parser.add_argument(\"-w\", \"--window\",type=int, default=65, help=\"the window of the output image\")\n",
    "parser.add_argument(\"-s\", \"--scaffold\", type=str, default = \"all_scaffold\", help=\"one scaffold you want to make image\")\n",
    "parser.add_argument(\"-c\", \"--core\", type=int, default=40, help=\"cores you want to use\")\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "fasta_df = read_fasta(args.inputfasta)\n",
    "sam = read_sam(args.inputsam)\n",
    "bed_name = args.inputbed\n",
    "scaffold_name = args.scaffold\n",
    "core = args.core\n",
    "window = args.window\n",
    "depth = 2\n",
    "expand = 0\n",
    "output = args.output\n",
    "\n",
    "consider_read_of_one_scaffold_by_bed_region(fasta_df, sam, bed_name, scaffold_name, core, window, depth, expand, output, ALL_TOUCH_INCLUDED = 0, ONLY_FILL_THE_LONGEST=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
