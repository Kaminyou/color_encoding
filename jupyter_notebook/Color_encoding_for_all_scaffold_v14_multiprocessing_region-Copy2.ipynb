{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "from Bio import SeqIO\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETTING\n",
    "pixel_max = 254 #Customerization\n",
    "\n",
    "# CHANNEL 0: BASE\n",
    "base_color_stride = 70 #Customerization\n",
    "offset_a_g = 40 #Customerization\n",
    "offset_t_c = 30 #Customerization\n",
    "\n",
    "# CHANNEL 1: BASE QUALITY\n",
    "default_quality = 0\n",
    "base_quality_cap = 40\n",
    "\n",
    "# CHANNEL 2: MAPPING QUALITY\n",
    "mapping_set_empty = 255 #Customerization\n",
    "mapping_quality_cap = 60 #Customerization\n",
    "\n",
    "# CHANNEL 3: ON POSITIVE STRAND\n",
    "set_empty = 255 #Customerization\n",
    "positive_strand = 70 #Customerization\n",
    "negative_strand = 240 #Customerization\n",
    "\n",
    "# CHANNEL 4: MATCH REFERENCE\n",
    "pixel_max = 254 #Customerization\n",
    "not_match_ref = pixel_max * 1 #Customerization\n",
    "match_ref = pixel_max * 0.2 #Customerization\n",
    "ref_not_provided = 255 #Customerization\n",
    "\n",
    "# TO RGB\n",
    "pixel_max_empty_def = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Color encoding\n",
    "'''\n",
    "# CHANNEL 1: Base quality\n",
    "    \n",
    "def base_to_color_full_array_input(x):\n",
    "    A = base_color_stride * 3 + offset_a_g\n",
    "    T = base_color_stride * 2 + offset_t_c\n",
    "    C = base_color_stride * 1 + offset_t_c\n",
    "    G = base_color_stride * 0 + offset_a_g\n",
    "    empty_to_fill = np.zeros(x.shape, dtype = np.int16)\n",
    "    empty_to_fill[x == \"A\"] = A\n",
    "    empty_to_fill[x == \"T\"] = T\n",
    "    empty_to_fill[x == \"C\"] = C\n",
    "    empty_to_fill[x == \"G\"] = G\n",
    "    empty_to_fill[x == \"a\"] = A\n",
    "    empty_to_fill[x == \"t\"] = T\n",
    "    empty_to_fill[x == \"c\"] = C\n",
    "    empty_to_fill[x == \"g\"] = G\n",
    "    empty_to_fill[x == \"N\"] = 0\n",
    "    empty_to_fill[x == \"D\"] = 0\n",
    "    return empty_to_fill\n",
    "\n",
    "\n",
    "# CHANNEL 1: Base quality\n",
    "Quality_Score_Encoding = {\"!\":0,\"\\\"\":1,\"#\":2,\"$\":3,\"%\":4,\"&\":5,\n",
    "                          \"\\'\":6,\"(\":7,\")\":8,\"*\":9,\"+\":10,\",\":11,\n",
    "                          \"-\":12,\".\":13,\"/\":14,\"0\":15,\"1\":16,\"2\":17,\"3\":18,\n",
    "                         \"4\":19,\"5\":20,\"6\":21,\"7\":22,\"8\":23,\"9\":24,\":\":25,\n",
    "                          \";\":26,\"<\":27,\"=\":28,\">\":29,\"?\":30,\"@\":31,\"A\":32,\n",
    "                         \"B\":33,\"C\":34,\"D\":35,\"E\":36,\"F\":37,\"G\":38,\"H\":39,\"I\":40}\n",
    "def base_quality_mapping(x):\n",
    "    if x in Quality_Score_Encoding.keys():\n",
    "        quailty = Quality_Score_Encoding[x]\n",
    "    else:\n",
    "        quailty = default_quality\n",
    "\n",
    "# CHANNEL 2: Mapping quality\n",
    "def mapping_quality_fill(array, mapping_quality):\n",
    "    \n",
    "    to_fill = min(mapping_quality, mapping_quality_cap) / mapping_quality_cap * pixel_max\n",
    "    mapping_quality_temp = np.full(array.shape, mapping_set_empty, dtype = np.int16)\n",
    "    mapping_quality_temp[array != \"\"] = to_fill\n",
    "    mapping_quality_temp[array == \"N\"] = mapping_set_empty\n",
    "    mapping_quality_temp[array == \"D\"] = mapping_set_empty\n",
    "    \n",
    "    return mapping_quality_temp\n",
    "    \n",
    "\n",
    "# CHANNEL 3: On positive strand\n",
    "def on_positive_strand_fill(array, positive_flag):\n",
    "    \n",
    "    on_positive_strand_temp = np.full(array.shape, set_empty, dtype = np.int16)\n",
    "    to_fill = positive_strand\n",
    "\n",
    "    binary_flag = np.binary_repr(positive_flag)\n",
    "    if (len(binary_flag) >= 5) and (list(binary_flag)[-5] == \"1\"):\n",
    "        to_fill = negative_strand\n",
    "    \n",
    "    on_positive_strand_temp[array != \"\"] = to_fill\n",
    "    on_positive_strand_temp[array == \"N\"] = set_empty\n",
    "    on_positive_strand_temp[array == \"D\"] = set_empty\n",
    "\n",
    "    return on_positive_strand_temp\n",
    "\n",
    "\n",
    "# CHANNEL 4: Match reference\n",
    "def match_ref_fill(depth, window, array):\n",
    "    \n",
    "    empty = np.full((depth, window), ref_not_provided, dtype = np.int16)\n",
    "    for i in np.arange(0, array.shape[1]):\n",
    "        for j in np.arange(1, array.shape[0]):\n",
    "            if array[j,i] == \"\":\n",
    "                break\n",
    "            elif array[j,i] == \"N\":\n",
    "                if array[0,i] == \"N\":\n",
    "                    break\n",
    "                else:\n",
    "                    empty[j,i] = not_match_ref\n",
    "            elif array[j,i] == array[0,i]:\n",
    "                empty[j,i] = match_ref\n",
    "            else:\n",
    "                empty[j,i] = ref_not_provided\n",
    "    return empty\n",
    "\n",
    "\n",
    "# COMBINE CHANNEL TO RGB\n",
    "def channels_to_RGB(pixel_max_empty_def,\n",
    "                    pre_image_base_color, \n",
    "                    pre_image_mapping_quality, \n",
    "                    pre_image_on_positive_strand, \n",
    "                    pre_image_match_ref, \n",
    "                    use_alpha = False):\n",
    "    if use_alpha == True: \n",
    "        alpha = pre_image_match_ref / pixel_max_empty_def\n",
    "        pre_image_base_color = np.multiply(pre_image_base_color, alpha)\n",
    "        pre_image_mapping_quality = np.multiply(pre_image_mapping_quality, alpha)\n",
    "        pre_image_on_positive_strand = np.multiply(pre_image_on_positive_strand, alpha)\n",
    "\n",
    "    RGB = np.empty((pre_image_base_color.shape[0],pre_image_base_color.shape[1],pre_image_base_color.shape[2],3), dtype = np.int16)\n",
    "    RGB[:,:,:,0] = pre_image_base_color\n",
    "    RGB[:,:,:,1] = pre_image_mapping_quality\n",
    "    RGB[:,:,:,2] = pre_image_on_positive_strand\n",
    "    return RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consecutive(data, stepsize=1):\n",
    "    return np.split(data, np.where(np.diff(data) != stepsize)[0]+1)\n",
    "\n",
    "def make_list_of_searching_interval_of_scaffold(scaffold_length, to_use_selected_scaffold_df):\n",
    "    mask = np.zeros(scaffold_length, dtype = bool)\n",
    "    searching_interval_selected = np.arange(1,(scaffold_length + 1))\n",
    "    searching_locus_list = pd.Series([np.arange(a, b) for a, b in zip(to_use_selected_scaffold_df[\"expand start\"], (to_use_selected_scaffold_df[\"expand end\"] + 1))], to_use_selected_scaffold_df.index)\n",
    "    for locus in searching_locus_list:\n",
    "        mask[locus] = True\n",
    "    searching_interval_unoverlapped = searching_interval_selected[mask]\n",
    "\n",
    "    return consecutive(searching_interval_unoverlapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Preprocessing\n",
    "'''\n",
    "def cigar_to_list(cigar): # NOT NEED TO USE THIS! THIS FUNCTION IS INCLUDED IN refine_read_by_cigar BELOW\n",
    "    '''\n",
    "    Deal with cigar \n",
    "    Split an unsplit cigar list to separated cigar array by number of each condition.\n",
    "    \n",
    "    2M3S1D2I to MMSSSDII\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    cigar : list\n",
    "        One element unseperated cigar list.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cigar_list : 1D numpy array\n",
    "        A array of cigar.\n",
    "    '''\n",
    "        \n",
    "    separate = np.array([s.strip() for s in re.split(r\"(\\D+)\", cigar)]) # Separate one element cigar list by cigar char \n",
    "    if separate[-1] == \"\": # Delete last empty element if it exists\n",
    "        separate = separate[:-1]\n",
    "\n",
    "\n",
    "    number = separate[::2].astype(int) # Extract number of each cigar\n",
    "    cigar = separate[1::2] # Extract char of cigar\n",
    "\n",
    "    # Cheack if number of elements in two list are same\n",
    "    if len(number) != len(cigar): \n",
    "        print(\"elements are not the same\")\n",
    "\n",
    "    # If number of elements are same, make a array of cigar\n",
    "    else:\n",
    "        cigar_list = []\n",
    "        for i in np.arange(0,len(number)):\n",
    "            for j in np.arange(0,number[i]):\n",
    "                cigar_list.append(cigar[i])\n",
    "        cigar_list = np.array(cigar_list)\n",
    "    \n",
    "    return cigar_list\n",
    "\n",
    "def refine_read_by_cigar(read, cigar): #PLEASE USE THIE TO MAKE REFINED READ FOR ALIGNMENT\n",
    "    '''\n",
    "    To refine reads by cigar list one by one.\n",
    "    \n",
    "    S : Directly delete it and move the behind forward\n",
    "    I : Extract to make a list of inserted element with position and delete it, moving the behind forward\n",
    "    D : Fill \"D\" in reads, move the behind backward\n",
    "    N : Fill \"N\" in reads, move the behind backward\n",
    "    M : Unchange\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    read : list\n",
    "        One element unseperated read list.\n",
    "    cigar : list\n",
    "        One element unseperated cigar list.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    refined_read : list\n",
    "        unseparated list of refined-read\n",
    "        \n",
    "    refined_read_insert : 1D numpy array\n",
    "        the inserted element\n",
    "    \n",
    "    refined_read_insert_index_at_ori_read : 1D numpy array\n",
    "        the index of inserted element in the original read (from 0)\n",
    "    \n",
    "    refined_read_insert_index_at_refined_read : 1D numpy array\n",
    "        the index of where to insert the inserted element on refined read (from 0)\n",
    "    '''\n",
    "    cigar_temp_list = cigar_to_list(cigar) # Read cigar and make cigar list by cigar_to_list function\n",
    "    read_temp_list = np.array(list(read)) # Make list of read\n",
    "\n",
    "    refined_read = [] # Make empty list for refined read\n",
    "    ori_read_index = 0 # To keep the original read index for insertion point\n",
    "    refined_read_index = 0 # To keep index of insertion point on refined read\n",
    "    refined_read_insert = [] # Make empty list to keep the insertion\n",
    "    refined_read_insert_index_at_ori_read = [] # FROM 0, make empty list to keep index of insertion on original read\n",
    "    refined_read_insert_index_at_refined_read = [] #FROM 0, make empty list to keep index of insertion on refined read\n",
    "    \n",
    "    # From the first cigar, fill the refined read one by one with original read dependent on the cigar\n",
    "    ## If cigar(+), ori-read(-):\n",
    "        ## \"D\", only refined-index move forward\n",
    "        ## \"N\", only refined-index move forward\n",
    "    ## If cigar(+), ori-read(+): \n",
    "        ## \"I\", only ori-index move forward, but save the information of insertion\n",
    "        ## \"S\", only ori-index move forward\n",
    "        ## \"M\", two of the index move forward\n",
    "    for index, cigar in enumerate(cigar_temp_list): \n",
    "        if cigar == \"S\": #Directly ignore it and move the behind forward\n",
    "            ori_read_index += 1 # Move forward on original index\n",
    "            continue\n",
    "        \n",
    "        if cigar == \"H\": #Directly ignore it and move the behind forward\n",
    "            continue\n",
    "            \n",
    "        if cigar == \"I\": #Extract to make a list of inserted element with position and ignore it, moving the behind forward\n",
    "            refined_read_insert.append(read_temp_list[ori_read_index]) # Save the base\n",
    "            refined_read_insert_index_at_ori_read.append(ori_read_index) # Save where it is on original read \n",
    "            refined_read_insert_index_at_refined_read.append(refined_read_index) # Save where it will be on refined read\n",
    "            ori_read_index += 1 # Move forward on original index\n",
    "            continue\n",
    "            \n",
    "        if cigar == \"D\": # Fill \"D\" in refined read\n",
    "            refined_read.append(\"D\") # Fill \"D\"\n",
    "            refined_read_index += 1 # Move forward on refined_read_index\n",
    "            continue\n",
    "            \n",
    "        if cigar == \"N\": # Fill \"N\" in refined read\n",
    "            refined_read.append(\"N\") # Fill \"N\"\n",
    "            refined_read_index += 1 # Move forward on refined_read_index\n",
    "            continue\n",
    "            \n",
    "        if cigar == \"M\": # Fill the base in refined read\n",
    "            refined_read.append(read_temp_list[ori_read_index]) # Fill the base\n",
    "            ori_read_index += 1 # Move forward on original read index\n",
    "            refined_read_index += 1 # Move forward on refined read index\n",
    "            continue\n",
    "            \n",
    "        else:\n",
    "            print(cigar,\"is not defined at\",index) # If there is any exception, print it\n",
    "            \n",
    "    refined_read = \"\".join(refined_read) # Combine list of the base pair \n",
    "    refined_read_insert = np.array(refined_read_insert)\n",
    "    refined_read_insert_index_at_ori_read = np.array(refined_read_insert_index_at_ori_read)\n",
    "    refined_read_insert_index_at_refined_read = np.array(refined_read_insert_index_at_refined_read)\n",
    "    return refined_read, refined_read_insert, refined_read_insert_index_at_ori_read, refined_read_insert_index_at_refined_read\n",
    "\n",
    "\n",
    "def find_insertion_forbackward(index, skip_range, window, read_selected_matrix, to_use_selected_scaffold_df):\n",
    "    '''\n",
    "    To find if there is any insertion in the window of one locus, \n",
    "    and make dataframes of insertion forward and backward respectively\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    index : int\n",
    "        The locus of scaffold.\n",
    "    skip range : int\n",
    "        The range skipped.\n",
    "    window : int\n",
    "        The window of one locus.\n",
    "    read_selected_matrix : numpy array\n",
    "        2D array that includes the information of reads covering one locus\n",
    "    to_use_selected_scaffold_df : pandas.DataFrame\n",
    "        \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    forward_df : pandas.DataFrame\n",
    "        a dataframe saving the information of forward insertion : read, index, base, read order\n",
    "        \n",
    "    backward_df : pandas.DataFrame\n",
    "        a dataframe saving the information of backward insertion : read, index, base, read order\n",
    "    '''\n",
    "    forward_i_read = []\n",
    "    forward_i_index = []\n",
    "    forward_i_base = []\n",
    "    forward_i_read_order = [] # FRPM 0 \n",
    "\n",
    "    backward_i_read = []\n",
    "    backward_i_index = []\n",
    "    backward_i_base = []\n",
    "    backward_i_read_order = [] # FROM 0\n",
    "    \n",
    "    # For every read that covers one locus\n",
    "    for read_order, reads in enumerate(read_selected_matrix[(index - skip_range)]): \n",
    "        \n",
    "        if np.isnan(reads): # Until no read, stop the iteration\n",
    "            break\n",
    "\n",
    "        refined_read_i_index = index - to_use_selected_scaffold_df[\"start\"][reads] # To find the index of the locus on one read\n",
    "        start_insertion_index = refined_read_i_index - ((window - 1) / 2) # To find the start point of one read that would be inside the window\n",
    "        end_insertion_index = refined_read_i_index + ((window - 1) / 2) - 1 # To find the end point of one read that would be inside the window\n",
    "        \n",
    "        # Check every insertion index of one read\n",
    "        for insertion_index in to_use_selected_scaffold_df[\"ori insertion index\"][reads]:\n",
    "            if refined_read_i_index <= insertion_index <= end_insertion_index: # If it is after the middle locus but before the end point\n",
    "                forward_i_read.append(reads) # Add the reads\n",
    "                forward_i_index.append(to_use_selected_scaffold_df[\"start\"][reads] + insertion_index) # Where to insert on original index of scaffold\n",
    "                forward_i_base.append(to_use_selected_scaffold_df[\"read\"][reads][insertion_index]) # Add the base\n",
    "                forward_i_read_order.append(read_order) # Add the read order which means the depth if plus 1 cause the first is ref  \n",
    "\n",
    "            elif start_insertion_index <= insertion_index <= (refined_read_i_index - 1): # If it is before the middle locus but after the end point\n",
    "                backward_i_read.append(reads) # Add the reads\n",
    "                backward_i_index.append(to_use_selected_scaffold_df[\"start\"][reads] + insertion_index) # Where to insert on original index of scaffold\n",
    "                backward_i_base.append(to_use_selected_scaffold_df[\"read\"][reads][insertion_index]) # Add the base\n",
    "                backward_i_read_order.append(read_order) # Add the read order which means the depth if plus 1 cause the first is ref  \n",
    "                \n",
    "    forward_df = pd.DataFrame({\"read\": forward_i_read, \"index\": forward_i_index, \"base\":forward_i_base, \"read order\":forward_i_read_order}) # Make the dataframe\n",
    "    backward_df = pd.DataFrame({\"read\": backward_i_read, \"index\": backward_i_index, \"base\":backward_i_base, \"read order\":backward_i_read_order}) # Make the dataframe\n",
    "    \n",
    "    return forward_df, backward_df\n",
    "\n",
    "\n",
    "def insertion_fill_in(index, depth, window, pre_image_char_part, forward_df, backward_df):\n",
    "    '''\n",
    "    If there is any insertion in the window of one locus,\n",
    "    insert it and move the other bases forward and backward \n",
    "    than delete the exceed\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    index : int\n",
    "        The locus of scaffold.\n",
    "    depth : int\n",
    "        The depth.\n",
    "    window : int\n",
    "        The window of one locus.\n",
    "    pre_image_char_part : 2D numpy array\n",
    "        The 2D array of one locus: pre_image_char_part = pre_image_char[(index - skip_range),:,:]\n",
    "    forward_df : pandas.DataFrame\n",
    "        The forward dataframe generated by find_insertion_forbackward function\n",
    "    backward_df : pandas.DataFrame\n",
    "        The backward dataframe generated by find_insertion_forbackward function\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pre_image_char_part_output : 2D numpy array\n",
    "        a new 2D array of one locus to replace the original one\n",
    "    '''\n",
    "    # To sort the forward dataframe, ascending order(1->2->3...)\n",
    "    forward_df = forward_df.sort_values(by = \"index\", ascending = True)\n",
    "    \n",
    "    # To extract read order, index, base from forward dataframe\n",
    "    for for_read_order, for_index, for_base in zip(forward_df[\"read order\"], forward_df[\"index\"], forward_df[\"base\"]):\n",
    "        insertion_location = int(for_index - index + ((window - 1) / 2)) # To find the insertion location in the window\n",
    "        insertion_array = np.chararray(depth, unicode = True) # Make a empty array to insert\n",
    "        insertion_array[for_read_order + 1] = for_base # Add the insertion base to the empty array\n",
    "        pre_image_char_part = np.insert(pre_image_char_part, insertion_location, insertion_array, 1) # Insert it\n",
    "    \n",
    "    # To sort the backward dataframe, descending order(3->2->1...)\n",
    "    backward_df = backward_df.sort_values(by = \"index\", ascending = False)\n",
    "    \n",
    "    # To count how many insertion backward for final cutting of the matrix\n",
    "    cut_length = len(backward_df)\n",
    "    \n",
    "    # To extract read order, index, base from backward dataframe\n",
    "    for back_read_order, back_index, back_base in zip(backward_df[\"read order\"], backward_df[\"index\"], backward_df[\"base\"]):\n",
    "        insertion_location = int(back_index - index + ((window - 1) / 2)) # To find the insertion location in the window\n",
    "        insertion_array = np.chararray(depth, unicode = True) # Make a empty array to insert\n",
    "        insertion_array[back_read_order + 1] = back_base # Add the insertion base to the empty array\n",
    "        pre_image_char_part = np.insert(pre_image_char_part, insertion_location, insertion_array, 1) # Insert it\n",
    "\n",
    "    # Cut the required part: if 2 backward insertion and 3 forward insertion with window, extract 2 : 2+window-1    \n",
    "    pre_image_char_part_output = pre_image_char_part[:,(cut_length):(cut_length + window)]\n",
    "    \n",
    "    return pre_image_char_part_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Read fasta file\n",
    "'''\n",
    "def read_fasta(fasta):\n",
    "    fasta_sequences = SeqIO.parse(open(fasta),\"fasta\")\n",
    "    fasta_name = []\n",
    "    fasta_sequence = []\n",
    "    for fasta in fasta_sequences:\n",
    "        name, sequence = fasta.id, str(fasta.seq)\n",
    "        fasta_name.append(name)\n",
    "        fasta_sequence.append(sequence)\n",
    "    fasta_dict = {\"scaffold\":fasta_name,\"sequence\":fasta_sequence}\n",
    "    fasta_df = pd.DataFrame(fasta_dict)\n",
    "    fasta_df[\"len\"] = fasta_df[\"sequence\"].str.len()\n",
    "    return fasta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Read sam file\n",
    "'''\n",
    "def read_sam(samfile):\n",
    "    # Read sam file\n",
    "    sam=[]\n",
    "    with open(samfile, \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            sam.append(line.split(\"\\t\"))\n",
    "    sam = np.array(sam)\n",
    "    return sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Scaffold fliter\n",
    "'''\n",
    "def scaffold_min_and_max(fasta_df):\n",
    "    minimum = int(input(\"Minimum: \"))\n",
    "    maximum = int(input(\"Maximum: \"))\n",
    "    mask_min = (fasta_df[\"len\"] >= minimum)\n",
    "    mask_max = (fasta_df[\"len\"] <= maximum)\n",
    "    fasta_df_fliter = fasta_df[(mask_min & mask_max)]\n",
    "    if len(fasta_df_fliter) == 0:\n",
    "        print(\"There is no scaffold match this length interval\")\n",
    "        return scaffold_min_and_max(fasta_df)\n",
    "    else:\n",
    "        print(\"Number of scaffold: \" + str(len(fasta_df_fliter)))\n",
    "        return fasta_df_fliter, minimum, maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "For each scaffold, find coveraging read in the sam\n",
    "'''\n",
    "def find_read_based_on_scaffold(scaffold_name, sam):\n",
    "    # Find index of selected scaffold in bam\n",
    "    scaffold_in_sam = list([i for i,item in enumerate(sam) if scaffold_name in item])\n",
    "\n",
    "    # Make a DataFrame for selected scaffold information\n",
    "\n",
    "    selected_scaffold_df = [sam[i] for i in scaffold_in_sam]\n",
    "    selected_scaffold_df = pd.DataFrame(selected_scaffold_df)\n",
    "    return selected_scaffold_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Select useful information in dafaframe of selected scaffold\n",
    "'''\n",
    "def make_read_scaffold_df(fasta_df, selected_scaffold_df, scaffold_name, expand = 0):\n",
    "    scaffold_length = fasta_df[fasta_df[\"scaffold\"] == scaffold_name][\"len\"].values[0]\n",
    "    \n",
    "    pd.options.mode.chained_assignment = None\n",
    "    to_use_selected_scaffold_df_pre = selected_scaffold_df[[1,2,3,4,5,9]]\n",
    "    to_use_selected_scaffold_df = to_use_selected_scaffold_df_pre[to_use_selected_scaffold_df_pre[9] != \"*\"]\n",
    "    to_use_selected_scaffold_df.columns = [\"flag\",\"scaffold\",\"start\",\"mapping quality\",\"cigar\",\"read\"]\n",
    "    to_use_selected_scaffold_df[\"read length\"] = to_use_selected_scaffold_df[\"read\"].str.len()\n",
    "    to_use_selected_scaffold_df[\"start\"] = to_use_selected_scaffold_df[\"start\"].astype('int64')\n",
    "    to_use_selected_scaffold_df[\"mapping quality\"] = to_use_selected_scaffold_df[\"mapping quality\"].astype('int64')\n",
    "    to_use_selected_scaffold_df[\"flag\"] = to_use_selected_scaffold_df[\"flag\"].astype('int64')\n",
    "    to_use_selected_scaffold_df[\"end\"] = (to_use_selected_scaffold_df[\"start\"] + to_use_selected_scaffold_df[\"read length\"] - 1)\n",
    "    to_use_selected_scaffold_df[\"refined_by_cigar\"] = to_use_selected_scaffold_df.apply(lambda x: refine_read_by_cigar(x[\"read\"], x[\"cigar\"]), axis=1)\n",
    "    to_use_selected_scaffold_df[[\"refined read\", \n",
    "                                 \"insertion\",\n",
    "                                 \"ori insertion index\",\n",
    "                                 \"re insertion index\"]] = pd.DataFrame(to_use_selected_scaffold_df[\"refined_by_cigar\"].tolist(), index=to_use_selected_scaffold_df.index)\n",
    "    to_use_selected_scaffold_df.drop(columns=[\"refined_by_cigar\"],inplace=True)\n",
    "    to_use_selected_scaffold_df[\"refined read length\"] = to_use_selected_scaffold_df[\"refined read\"].str.len()\n",
    "    to_use_selected_scaffold_df[\"refined end\"] = (to_use_selected_scaffold_df[\"start\"] + to_use_selected_scaffold_df[\"refined read length\"] - 1)\n",
    "    to_use_selected_scaffold_df[\"expand start\"] = (to_use_selected_scaffold_df[\"start\"] - expand)\n",
    "    to_use_selected_scaffold_df.loc[to_use_selected_scaffold_df[\"expand start\"] < 1, \"expand start\"] = 1\n",
    "    to_use_selected_scaffold_df[\"expand end\"] = (to_use_selected_scaffold_df[\"refined end\"] + expand)\n",
    "    to_use_selected_scaffold_df.loc[to_use_selected_scaffold_df[\"expand end\"] > scaffold_length, \"expand end\"] = scaffold_length\n",
    "    \n",
    "    return to_use_selected_scaffold_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Make a matrix of reads which meet the criteria of each locus\n",
    "'''\n",
    "def make_read_selected_matrix_find_reads(to_use_selected_scaffold_df, ALL_TOUCH_INCLUDED, window, depth, ONLY_FILL_THE_LONGEST, index):\n",
    "    mask1 = to_use_selected_scaffold_df[\"start\"] <= index + ALL_TOUCH_INCLUDED * ((window + 1) / 2)\n",
    "    mask2 = to_use_selected_scaffold_df[\"refined end\"] >= index + ALL_TOUCH_INCLUDED * ((window + 1) / 2)\n",
    "    read_selected_array = np.empty(depth)\n",
    "    read_selected_array[:] = np.nan\n",
    "    if ONLY_FILL_THE_LONGEST == True:\n",
    "        if len(to_use_selected_scaffold_df[(mask1 & mask2)][\"read length\"]) != 0:\n",
    "            read_selected_array[0:1] = to_use_selected_scaffold_df[(mask1 & mask2)][\"read length\"].idxmax()\n",
    "        \n",
    "    else:\n",
    "        length = len(to_use_selected_scaffold_df[(mask1 & mask2)].index)\n",
    "        read_selected_array[0:length] = to_use_selected_scaffold_df[(mask1 & mask2)].index\n",
    "    \n",
    "    return read_selected_array\n",
    "\n",
    "def make_read_selected_matrix(scaffold_name, searching_interval, to_use_selected_scaffold_df, ALL_TOUCH_INCLUDED, window, skip_range, depth, ONLY_FILL_THE_LONGEST, core):\n",
    "    \n",
    "    # Interval for searching\n",
    "    searching_interval_length = len(searching_interval)\n",
    "\n",
    "    # Search every base that are in this interval\n",
    "    # And select feasible reads for each base on locus of genome\n",
    "    if __name__ == \"__main__\" :  \n",
    "        \n",
    "        pool = Pool(core) # Pool() \n",
    "        func = partial(make_read_selected_matrix_find_reads, to_use_selected_scaffold_df, ALL_TOUCH_INCLUDED, window, depth, ONLY_FILL_THE_LONGEST)\n",
    "        read_selected_matrix = pool.map(func, searching_interval) \n",
    "        pool.close()  \n",
    "        pool.join()   \n",
    "    \n",
    "    read_selected_matrix = np.array(read_selected_matrix)\n",
    "        \n",
    "    return read_selected_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Make a 4 dimension matrix of pre-image base \n",
    "'''\n",
    "def image_pileup_Parallelism(scaffold_name, fasta_df, to_use_selected_scaffold_df, \n",
    "                             read_selected_matrix, depth, window, skip_range, \n",
    "                             on_positive_strand_not_provide, index, INSERTION = False, \n",
    "                             REVERSE_FOR_NEG = True):\n",
    "    # To search the base based on index\n",
    "    # From index=0~the last one, means from the first one to the last\n",
    "    pre_pre_image_char_matrix = np.chararray((depth, window), unicode = True)\n",
    "    # FIRST!!! FILL ref at depth=0\n",
    "    # From start point \"0\" to end point \"window - 1\" \n",
    "    middle = ((window - 1) / 2) # Index not order\n",
    "    scaffold_max_length = fasta_df[fasta_df[\"scaffold\"] == scaffold_name][\"len\"].values[0]\n",
    "\n",
    "    # at \"0\" fill: (index - middle)\n",
    "    # at \"coverage interval - 1\" fill: (index + middle) \n",
    "    # This is index of what to fill\n",
    "    fasta_fill_index_start = (index - middle) # Order not index\n",
    "    fasta_fill_index_end = (index + middle) # Order not index\n",
    "\n",
    "    # Set all the element to \"N\" first\n",
    "    pre_pre_image_char_matrix[0, :] = \"N\"\n",
    "    base_fill_index_start = 0\n",
    "    base_fill_index_end = window\n",
    "    if fasta_fill_index_start < 1:\n",
    "        base_fill_index_start = int(np.abs(fasta_fill_index_start - 1))\n",
    "        fasta_fill_index_start = 1\n",
    "\n",
    "    elif fasta_fill_index_end > scaffold_max_length:\n",
    "        base_fill_index_end = int((scaffold_max_length - fasta_fill_index_end))\n",
    "        fasta_fill_index_end = scaffold_max_length\n",
    "    \n",
    "    pre_pre_image_char_matrix[0, base_fill_index_start:base_fill_index_end] = np.array(list(fasta_df[fasta_df[\"scaffold\"]==scaffold_name][\"sequence\"].values[0][int(fasta_fill_index_start - 1):int(fasta_fill_index_end)]))   \n",
    "    \n",
    "    for i, reads in enumerate(read_selected_matrix[(index - skip_range)]):\n",
    "        # If there is no read or until the end of the coverage, jump to the next locus\n",
    "        if np.isnan(reads):\n",
    "            break\n",
    "\n",
    "        else:\n",
    "            read_start = to_use_selected_scaffold_df[\"start\"][reads] # To find the start point of the read\n",
    "            read_end = to_use_selected_scaffold_df[\"refined end\"][reads] # To find the end point of the read\n",
    "\n",
    "            pre_pre_image_char_matrix[(i+1), :] = \"N\"\n",
    "            image_read_fill_start = 0\n",
    "            image_read_fill_end = int(window)\n",
    "            read_fill_start = int(fasta_fill_index_start - read_start)\n",
    "            read_fill_end = int(fasta_fill_index_end - read_start) + 1\n",
    "\n",
    "            if read_start > fasta_fill_index_start:\n",
    "                image_read_fill_start = int(read_start - fasta_fill_index_start)\n",
    "                if len(pre_pre_image_char_matrix[(i+1), image_read_fill_start:image_read_fill_end]) != len(np.array(list(to_use_selected_scaffold_df[\"refined read\"][reads][:read_fill_end]))):\n",
    "                    print((index - skip_range), (read_end), (read_start))\n",
    "                    print( (index - skip_range), image_read_fill_start, image_read_fill_end, read_fill_end )\n",
    "                    print(len(pre_pre_image_char_matrix[(i+1), image_read_fill_start:image_read_fill_end]))\n",
    "                    print(len(np.array(list(to_use_selected_scaffold_df[\"refined read\"][reads][:read_fill_end]))))\n",
    "                    print(to_use_selected_scaffold_df[\"refined read\"][reads][:read_fill_end + 2])\n",
    "                else: \n",
    "                    print(\"pass \", (index - skip_range), image_read_fill_start, image_read_fill_end, read_fill_end )\n",
    "                    print(len(pre_pre_image_char_matrix[(i+1), image_read_fill_start:image_read_fill_end]))\n",
    "                    print(len(np.array(list(to_use_selected_scaffold_df[\"refined read\"][reads][:read_fill_end]))))\n",
    "                    print(to_use_selected_scaffold_df[\"refined read\"][reads][:read_fill_end])\n",
    "                pre_pre_image_char_matrix[(i+1), image_read_fill_start:image_read_fill_end] = np.array(list(to_use_selected_scaffold_df[\"refined read\"][reads][:read_fill_end]))\n",
    "                \n",
    "\n",
    "            elif read_end < fasta_fill_index_end:\n",
    "                image_read_fill_end = int(read_end - fasta_fill_index_end)\n",
    "                pre_pre_image_char_matrix[(i+1), image_read_fill_start:image_read_fill_end] = np.array(list(to_use_selected_scaffold_df[\"refined read\"][reads][read_fill_start:]))\n",
    "\n",
    "            else:    \n",
    "                pre_pre_image_char_matrix[(i+1), image_read_fill_start:image_read_fill_end] = np.array(list(to_use_selected_scaffold_df[\"refined read\"][reads][read_fill_start:read_fill_end]))\n",
    "    \n",
    "    ##################### DEAL WITH N #######################################\\\n",
    "    for i in np.arange(0, pre_pre_image_char_matrix.shape[1]): # For all the element in the window\n",
    "        if pre_pre_image_char_matrix[0, i] == \"N\": # Check the top element is \"N\" or not\n",
    "            A = np.count_nonzero(pre_pre_image_char_matrix[:, i] == \"A\") # Count \"A\" \n",
    "            T = np.count_nonzero(pre_pre_image_char_matrix[:, i] == \"T\") # Count \"T\"\n",
    "            C = np.count_nonzero(pre_pre_image_char_matrix[:, i] == \"C\") # Count \"C\"\n",
    "            G = np.count_nonzero(pre_pre_image_char_matrix[:, i] == \"G\") # Count \"G\"\n",
    "            N = np.count_nonzero(pre_pre_image_char_matrix[:, i] == \"N\") # Count \"N\"\n",
    "\n",
    "            base_count_list = np.array([A, T, C, G, N]) # Make a list of base\n",
    "            base_unique_list = np.array([\"A\", \"T\", \"C\", \"G\", \"N\"]) # Make a list of index of the base\n",
    "            base_count_list_sort = np.sort(base_count_list) # Sort the list of base\n",
    "            if base_count_list_sort[-1] != base_count_list_sort[-2]: # To check if there any duplicated most frequent elements\n",
    "                pre_pre_image_char_matrix[0, i] == base_unique_list[base_count_list.argmax()] # If no, fill the most frequent one\n",
    "    \n",
    "    ####################################### INSERTION #######################################\n",
    "    if INSERTION == True:\n",
    "        forward_df, backward_df = find_insertion_forbackward(index, skip_range, window, read_selected_matrix, to_use_selected_scaffold_df)\n",
    "        if (len(forward_df) != 0) or  (len(backward_df) != 0): # If there is any insertion, use pre_image_char function\n",
    "            pre_pre_image_char_matrix = insertion_fill_in(index, depth, window, pre_pre_image_char_matrix, forward_df, backward_df)\n",
    "            \n",
    "    ####################################### REVERSE STRAND IF ON NEGATIVE STRAND #######################################\n",
    "    if REVERSE_FOR_NEG == True:\n",
    "        if pre_pre_image_char_matrix.shape[0] == 2:\n",
    "            reads = read_selected_matrix[(index - skip_range)][0]\n",
    "            if not np.isnan(reads):\n",
    "                positive_flag = to_use_selected_scaffold_df[\"flag\"][reads]\n",
    "                binary_flag = np.binary_repr(positive_flag)\n",
    "                if (len(binary_flag) >= 5) and (list(binary_flag)[-5] == \"1\"):\n",
    "                    pre_pre_image_char_matrix = np.flip(pre_pre_image_char_matrix, axis = 1)\n",
    "                    reverse_temp = pre_pre_image_char_matrix\n",
    "                    reverse_temp[pre_pre_image_char_matrix == \"A\"] = \"T\"\n",
    "                    reverse_temp[pre_pre_image_char_matrix == \"T\"] = \"A\"\n",
    "                    reverse_temp[pre_pre_image_char_matrix == \"C\"] = \"G\"\n",
    "                    reverse_temp[pre_pre_image_char_matrix == \"G\"] = \"C\"\n",
    "                    pre_pre_image_char_matrix = reverse_temp\n",
    "        else:\n",
    "            print(\"REVERSE_FOR_NEG is only for depth=2\")\n",
    "    \n",
    "    ####################################### COLOR\n",
    "    pre_image_base_color = base_to_color_full_array_input(pre_pre_image_char_matrix) \n",
    "    \n",
    "    ####################################### MAPPING QUALITY\n",
    "    pre_image_mapping_quality_temp = np.full(pre_pre_image_char_matrix.shape, mapping_set_empty)\n",
    "    \n",
    "    for i, reads in enumerate(read_selected_matrix[(index - skip_range)]):\n",
    "        # If there is no read or until the end of the coverage, jump to the next locus\n",
    "        if np.isnan(reads):\n",
    "            break\n",
    "        else:\n",
    "            mapping_quality = to_use_selected_scaffold_df[\"mapping quality\"][reads]\n",
    "            pre_image_mapping_quality_temp[(i + 1), :] = mapping_quality_fill(pre_pre_image_char_matrix[(i+1), :], mapping_quality)\n",
    "    ####################################### ON POSITIVE STRAND\n",
    "    on_positive_strand_temp = np.full(pre_pre_image_char_matrix.shape, on_positive_strand_not_provide)\n",
    "    \n",
    "    for i, reads in enumerate(read_selected_matrix[(index - skip_range)]):\n",
    "        # If there is no read or until the end of the coverage, jump to the next locus\n",
    "        if np.isnan(reads):\n",
    "            break\n",
    "        else:\n",
    "            positive_flag = to_use_selected_scaffold_df[\"flag\"][reads]\n",
    "            on_positive_strand_temp[(i + 1), :] = on_positive_strand_fill(pre_pre_image_char_matrix[(i+1), :], positive_flag)\n",
    "    ####################################### MATCH REF\n",
    "    pre_image_match_ref_temp = match_ref_fill(depth, window, pre_pre_image_char_matrix)\n",
    "    \n",
    "    return pre_image_base_color, pre_image_mapping_quality_temp, on_positive_strand_temp, pre_image_match_ref_temp\n",
    "\n",
    "\n",
    "def image_pileup(scaffold_name, \n",
    "                 fasta_df, \n",
    "                 read_selected_matrix, \n",
    "                 to_use_selected_scaffold_df, \n",
    "                 window, \n",
    "                 depth, \n",
    "                 skip_range,\n",
    "                 searching_interval, \n",
    "                 pixel_max, \n",
    "                 bias_of_read, \n",
    "                 mapping_quality_not_provide, \n",
    "                 on_positive_strand_not_provide, \n",
    "                 not_match_ref, core):\n",
    "    \n",
    "    # 3 dimention maxtrix initialization: base(char), base color(int), base quality(char), on postive strand(int)\n",
    "    ## x: searching_interval \n",
    "    ## y: depth\n",
    "    ## z: coverage read interval\n",
    "    ####coverage_interval = (length_of_read * 2 -1 + bias_of_read) \n",
    "    window = 149\n",
    "    searching_interval_length = len(searching_interval)\n",
    "\n",
    "    scaffold_max_length = fasta_df[fasta_df[\"scaffold\"] == scaffold_name][\"len\"].values[0]\n",
    "    middle = ((window - 1) / 2) # Index not order\n",
    "    \n",
    "    # FIRST!!! FILL REF\n",
    "    # SECOND!!! FILL read at depth=1~\n",
    "    if __name__ == \"__main__\" :  \n",
    "        pre_image_base_color = []\n",
    "        pre_image_mapping_quality = []\n",
    "        pre_image_on_positive_strand = []\n",
    "        pre_image_match_ref = []\n",
    "        \n",
    "        \n",
    "        \n",
    "        pool = Pool(core) # Pool() \n",
    "        func = partial(image_pileup_Parallelism, scaffold_name, fasta_df, to_use_selected_scaffold_df, read_selected_matrix, depth, window, skip_range, on_positive_strand_not_provide)\n",
    "        for pre_image_base_color_locus, pre_image_mapping_quality_locus, pre_image_on_positive_strand_locus,pre_image_match_ref_locus in pool.map(func, searching_interval, chunksize=1000): \n",
    "            pre_image_base_color.append(pre_image_base_color_locus)\n",
    "            pre_image_mapping_quality.append(pre_image_mapping_quality_locus)\n",
    "            pre_image_on_positive_strand.append(pre_image_on_positive_strand_locus)\n",
    "            pre_image_match_ref.append(pre_image_match_ref_locus)\n",
    "            \n",
    "        pool.close()  \n",
    "        pool.join()  \n",
    "        \n",
    "    #pre_image_char = np.array(pre_image_char)\n",
    "    pre_image_base_color = np.array(pre_image_base_color)\n",
    "    pre_image_mapping_quality = np.array(pre_image_mapping_quality)\n",
    "    pre_image_on_positive_strand = np.array(pre_image_on_positive_strand)\n",
    "    pre_image_match_ref = np.array(pre_image_match_ref)\n",
    "    \n",
    " \n",
    "    return pre_image_base_color, pre_image_mapping_quality, pre_image_on_positive_strand, pre_image_match_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Visualization of one locus\n",
    "'''\n",
    "def visualization_locus(locus, RGB):\n",
    "    final_plot = RGB\n",
    "    final_index = locus\n",
    "    print(final_index)\n",
    "\n",
    "    plt.figure(figsize=(30,5))\n",
    "    plt.subplot(4,1,1)\n",
    "    plt.imshow(final_plot[final_index,:,:,:])\n",
    "    plt.title(\"Locus = %s\" %locus)\n",
    "    plt.ylabel(\"RGB\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(50,5))\n",
    "    plt.subplot(4,2,2)\n",
    "    plt.imshow(final_plot[final_index,:,:,0],cmap='gray')\n",
    "    plt.ylabel(\"Base\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(60,5))\n",
    "    plt.subplot(4,3,3)\n",
    "    plt.imshow(final_plot[final_index,:,:,1],cmap='gray')\n",
    "    plt.ylabel(\"Mapping quality\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(80,5))\n",
    "    plt.subplot(4,4,4)\n",
    "    plt.imshow(final_plot[final_index,:,:,2],cmap='gray')\n",
    "    plt.ylabel(\"On positive strand\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def consider_only_scaffold(fasta_df, sam, minimum, maximum, core, ALL_TOUCH_INCLUDED = 0, window =149, depth=10, skip_range=1, ONLY_FILL_THE_LONGEST=False):\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    scaffold_image_dict = {}\n",
    "\n",
    "    total_count = len(fasta_df)\n",
    "\n",
    "    # For each scaffold \n",
    "    for count, scaffold_name in enumerate(fasta_df[\"scaffold\"]):\n",
    "        start_time_scaffold = datetime.now()\n",
    "        print(\"Start \",scaffold_name ,\" | \" ,(count + 1), \"/\", total_count, \" | \", round((count + 1) * 100/total_count, 4), \"%\")\n",
    "\n",
    "        # Select useful information in dafaframe of selected scaffold\n",
    "        selected_scaffold_df = find_read_based_on_scaffold(scaffold_name, sam)\n",
    "\n",
    "        if len(selected_scaffold_df) == 0:\n",
    "            print(\"no covered reads\")\n",
    "            print(\"==========================================\")\n",
    "            continue\n",
    "\n",
    "        to_use_selected_scaffold_df = make_read_scaffold_df(fasta_df, selected_scaffold_df, scaffold_name)\n",
    "        to_use_selected_scaffold_df = to_use_selected_scaffold_df.sort_values(by=[\"start\"]) # Sort the reads by start locus\n",
    "\n",
    "        # Make a matrix of reads which meet the criteria of each locus\n",
    "        # Setting\n",
    "        #ALL_TOUCH_INCLUDED = 0 # Customerized: 0=False, 1=True\n",
    "        #window = 149 # Please mide if ALL_TOUCH_INCLUDED is True, the setting must be same as the one in the pileup cell \n",
    "        #skip_range = 15000 #Customerization # MUST START FROM 1\n",
    "        #depth = 10 #Customerization\n",
    "        searching_interval = np.arange(skip_range, (fasta_df[fasta_df[\"scaffold\"] == scaffold_name][\"len\"].values[0] + 1 )) \n",
    "        #searching_interval = np.arange(15000,16000)\n",
    "\n",
    "        print(\"Step 1: finding reads\", end='')\n",
    "\n",
    "        start_time_temp = datetime.now()\n",
    "        read_selected_matrix = make_read_selected_matrix(scaffold_name, \n",
    "                                                         searching_interval, \n",
    "                                                         to_use_selected_scaffold_df, \n",
    "                                                         ALL_TOUCH_INCLUDED, \n",
    "                                                         window, skip_range, \n",
    "                                                         depth, ONLY_FILL_THE_LONGEST, core)\n",
    "        end_time_temp  = datetime.now()\n",
    "        print(\" | Duration: {}\".format(end_time_temp - start_time_temp))\n",
    "\n",
    "\n",
    "        # Make a 3 dimension image\n",
    "        pixel_max = 254  #Customerization\n",
    "        bias_of_read = 0 #Customerization\n",
    "        mapping_quality_not_provide = 255 #Customerization\n",
    "        on_positive_strand_not_provide = 255 #Customerization\n",
    "        not_match_ref = pixel_max * 1 #Customerization\n",
    "\n",
    "        print(\"Step 2: image pileup\", end='')\n",
    "        start_time_temp = datetime.now()\n",
    "        pre_image_base_color, pre_image_mapping_quality, pre_image_on_positive_strand, pre_image_match_ref = image_pileup(scaffold_name,\n",
    "                                 fasta_df, \n",
    "                                 read_selected_matrix, \n",
    "                                 to_use_selected_scaffold_df, \n",
    "                                 window, \n",
    "                                 depth, \n",
    "                                 skip_range,                                                                               \n",
    "                                 searching_interval, \n",
    "                                 pixel_max, \n",
    "                                 bias_of_read, \n",
    "                                 mapping_quality_not_provide, \n",
    "                                 on_positive_strand_not_provide, \n",
    "                                 not_match_ref, core)\n",
    "        end_time_temp  = datetime.now()\n",
    "        print(\" | Duration: {}\".format(end_time_temp - start_time_temp))\n",
    "\n",
    "        print(\"Step 3: combination\", end='')\n",
    "        start_time_temp = datetime.now()\n",
    "        FINAL_RGB = channels_to_RGB(pixel_max_empty_def,\n",
    "                                pre_image_base_color, \n",
    "                                pre_image_mapping_quality, \n",
    "                                pre_image_on_positive_strand, \n",
    "                                pre_image_match_ref, \n",
    "                                use_alpha = False)\n",
    "        end_time_temp  = datetime.now()\n",
    "        print(\" | Duration: {}\".format(end_time_temp - start_time_temp))\n",
    "\n",
    "        # Save to dictionary\n",
    "        print(\"Step 4: save to dictionary\", end='')\n",
    "        start_time_temp = datetime.now()\n",
    "        scaffold_image_dict[scaffold_name] = FINAL_RGB\n",
    "        end_time_temp  = datetime.now()\n",
    "        print(\" | Duration: {}\".format(end_time_temp - start_time_temp))\n",
    "\n",
    "\n",
    "        end_time_scaffold = datetime.now()\n",
    "        print(\"finish \",scaffold_name, end='')\n",
    "        print(\" | Duration: {}\".format(end_time_scaffold - start_time_scaffold))\n",
    "        print(\"==========================================\")\n",
    "\n",
    "    print(\"Final stage: save to pickle\")\n",
    "    # Store data to pickle(serialize)\n",
    "    save_name = \"termite_g2_scaffold_image_dict_\" + str(round(minimum/1000)) + \"K_\" + str(round(maximum/1000)) +\"K.pickle\"\n",
    "    with open(save_name, \"wb\") as handle:\n",
    "        pickle.dump(scaffold_image_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    end_time = datetime.now()\n",
    "    print(\"Total duration: {}\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def consider_read_of_scaffold(fasta_df, sam, minimum, maximum, core, ALL_TOUCH_INCLUDED = 0, window =149, depth=2, expand = 1000, ONLY_FILL_THE_LONGEST=True):\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    scaffold_image_dict = {}\n",
    "\n",
    "    total_count = len(fasta_df)\n",
    "\n",
    "    for count, scaffold_name in enumerate(fasta_df[\"scaffold\"]):\n",
    "        scaffold_length = fasta_df[fasta_df[\"scaffold\"] == scaffold_name][\"len\"].values[0]\n",
    "        start_time_scaffold = datetime.now()\n",
    "\n",
    "        print(\"Start \",scaffold_name ,\" | \" ,(count + 1), \"/\", total_count, \" | \", round((count + 1) * 100/total_count, 4), \"%\")\n",
    "        print(\"==================================================================================\")\n",
    "\n",
    "        # Select useful information in dafaframe of selected scaffold\n",
    "        selected_scaffold_df = find_read_based_on_scaffold(scaffold_name, sam)\n",
    "\n",
    "        if len(selected_scaffold_df) == 0:\n",
    "            print(\"no covered reads\")\n",
    "            print(\"==========================================\")\n",
    "            continue\n",
    "\n",
    "        to_use_selected_scaffold_df = make_read_scaffold_df(fasta_df, selected_scaffold_df, scaffold_name, expand)\n",
    "        to_use_selected_scaffold_df = to_use_selected_scaffold_df.sort_values(by=[\"start\"]) # Sort the reads by start locus\n",
    "\n",
    "        searching_interval_unoverlapped = make_list_of_searching_interval_of_scaffold(scaffold_length, to_use_selected_scaffold_df)\n",
    "\n",
    "        # Make a matrix of reads which meet the criteria of each locus\n",
    "        # Setting\n",
    "        #ALL_TOUCH_INCLUDED = 0 # Customerized: 0=False, 1=True\n",
    "        #window = 149 # Please mide if ALL_TOUCH_INCLUDED is True, the setting must be same as the one in the pileup cell \n",
    "        #skip_range = 1 #Customerization # MUST START FROM 1\n",
    "        #depth = 2 #Customerization\n",
    "        ####searching_interval = np.arange(skip_range, (fasta_df[fasta_df[\"scaffold\"] == scaffold_name][\"len\"].values[0] + 1 )) \n",
    "\n",
    "        for fragment in searching_interval_unoverlapped:\n",
    "            searching_interval = fragment\n",
    "            skip_range = fragment[0] #Customerization # MUST START FROM 1\n",
    "            start_time_fragment = datetime.now()\n",
    "\n",
    "            store_name = scaffold_name + \"|\" + str(fragment[0]) + \" to \" + str(fragment[-1])\n",
    "            print(\"Start \",store_name)\n",
    "            print(\"Step 1: finding reads\", end='')\n",
    "            start_time_temp = datetime.now()\n",
    "            read_selected_matrix = make_read_selected_matrix(scaffold_name, \n",
    "                                                             searching_interval, \n",
    "                                                             to_use_selected_scaffold_df, \n",
    "                                                             ALL_TOUCH_INCLUDED,\n",
    "                                                             window, skip_range, \n",
    "                                                             depth, ONLY_FILL_THE_LONGEST, core)\n",
    "            end_time_temp  = datetime.now()\n",
    "            print(\" | Duration: {}\".format(end_time_temp - start_time_temp))\n",
    "\n",
    "\n",
    "            # Make a 3 dimension image\n",
    "            pixel_max = 254  #Customerization\n",
    "            bias_of_read = 0 #Customerization\n",
    "            mapping_quality_not_provide = 255 #Customerization\n",
    "            on_positive_strand_not_provide = 255 #Customerization\n",
    "            not_match_ref = pixel_max * 1 #Customerization\n",
    "\n",
    "            print(\"Step 2: image pileup\", end='')\n",
    "            start_time_temp = datetime.now()\n",
    "            pre_image_base_color, pre_image_mapping_quality, pre_image_on_positive_strand, pre_image_match_ref = image_pileup(scaffold_name,\n",
    "                                     fasta_df, \n",
    "                                     read_selected_matrix, \n",
    "                                     to_use_selected_scaffold_df, \n",
    "                                     window, \n",
    "                                     depth,\n",
    "                                     skip_range,\n",
    "                                     searching_interval, \n",
    "                                     pixel_max, \n",
    "                                     bias_of_read, \n",
    "                                     mapping_quality_not_provide, \n",
    "                                     on_positive_strand_not_provide, \n",
    "                                     not_match_ref, core)\n",
    "            end_time_temp  = datetime.now()\n",
    "            print(\" | Duration: {}\".format(end_time_temp - start_time_temp))\n",
    "\n",
    "            print(\"Step 3: combination\", end='')\n",
    "            start_time_temp = datetime.now()\n",
    "            FINAL_RGB = channels_to_RGB(pixel_max_empty_def,\n",
    "                                    pre_image_base_color, \n",
    "                                    pre_image_mapping_quality, \n",
    "                                    pre_image_on_positive_strand, \n",
    "                                    pre_image_match_ref, \n",
    "                                    use_alpha = False)\n",
    "            end_time_temp  = datetime.now()\n",
    "            print(\" | Duration: {}\".format(end_time_temp - start_time_temp))\n",
    "\n",
    "            # Save to dictionary\n",
    "            print(\"Step 4: save to dictionary\", end='')\n",
    "\n",
    "\n",
    "            start_time_temp = datetime.now()\n",
    "            scaffold_image_dict[store_name] = FINAL_RGB\n",
    "            end_time_temp  = datetime.now()\n",
    "            print(\" | Duration: {}\".format(end_time_temp - start_time_temp))\n",
    "\n",
    "\n",
    "            end_time_fragment = datetime.now()\n",
    "            print(\"finish \",store_name, end='')\n",
    "            print(\" | Duration: {}\".format(end_time_fragment - start_time_fragment))\n",
    "            print(\"==========================================\")\n",
    "\n",
    "        end_time_scaffold = datetime.now()\n",
    "        print(\"finish \",scaffold_name, end='')\n",
    "        print(\" | Duration: {}\".format(end_time_scaffold - start_time_scaffold))\n",
    "        print(\"==================================================================================\")\n",
    "\n",
    "    print(\"Final stage: save to pickle\")\n",
    "    # Store data to pickle(serialize)\n",
    "    save_name = \"termite_g2_scaffold_image_dict_\" + str(round(minimum/1000)) + \"K_\" + str(round(maximum/1000)) +\"K_fragment.pickle\"\n",
    "    with open(save_name, \"wb\") as handle:\n",
    "        pickle.dump(scaffold_image_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    end_time = datetime.now()\n",
    "    print(\"Total duration: {}\".format(end_time - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_encoding_combination(ONLY_CONSIDER_READ = True, ALL_TOUCH_INCLUDED = 0, window =149, depth=2, expand = 1000, core=40):\n",
    "    fasta_df_ori_name = input(\"Please enter ref_fasta file: \")\n",
    "    sam_name = input(\"Please enter sam file: \")\n",
    "    \n",
    "    fasta_df_ori = read_fasta(fasta_df_ori_name)\n",
    "    sam = read_sam(sam_name)\n",
    "    \n",
    "    fasta_df, minimum, maximum = scaffold_min_and_max(fasta_df_ori)\n",
    "    print(\"======================================Setting correct====================================\")\n",
    "    if ONLY_CONSIDER_READ == True:\n",
    "        if depth != 2:\n",
    "            sys.exit(\"ERROR! If consider read of scaffold, depth must set to be 2\")\n",
    "        consider_read_of_scaffold(fasta_df, sam, minimum, maximum, core, ALL_TOUCH_INCLUDED, window, depth, expand)\n",
    "    else:\n",
    "        consider_only_scaffold(fasta_df, sam, minimum, maximum, core, ALL_TOUCH_INCLUDED, window, depth, skip_range=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Input\n",
    "## Input fasta file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter ref_fasta file: termite_genome2.fasta\n",
      "Please enter sam file: termite_g2.sam\n",
      "Minimum: 9000000\n",
      "Maximum: 10000000\n",
      "Number of scaffold: 3\n",
      "======================================Setting correct====================================\n",
      "Start  NewScaf52  |  1 / 3  |  33.3333 %\n",
      "==================================================================================\n",
      "Start  NewScaf52|79738 to 81833\n",
      "Step 1: finding reads | Duration: 0:00:03.362418\n",
      "Step 2: image pileuppass  1000 73 149 76\n",
      "76\n",
      "76\n",
      "CTAGGAGTCGAGATCCATGATGTGTGCACTTGCTTGGAACAACAGACGAAGATTGCTGGCCGTGCGGTTGTTTTTA\n",
      "pass  1001 72 149 77\n",
      "77\n",
      "77\n",
      "CTAGGAGTCGAGATCCATGATGTGTGCACTTGCTTGGAACAACAGACGAAGATTGCTGGCCGTGCGGTTGTTTTTAC\n",
      "pass  1002 71 149 78\n",
      "78\n",
      "78\n",
      "CTAGGAGTCGAGATCCATGATGTGTGCACTTGCTTGGAACAACAGACGAAGATTGCTGGCCGTGCGGTTGTTTTTACG\n",
      "pass  1003 70 149 79\n",
      "79\n",
      "79\n",
      "CTAGGAGTCGAGATCCATGATGTGTGCACTTGCTTGGAACAACAGACGAAGATTGCTGGCCGTGCGGTTGTTTTTACGC\n",
      "pass  1004 69 149 80\n",
      "80\n",
      "80\n",
      "CTAGGAGTCGAGATCCATGATGTGTGCACTTGCTTGGAACAACAGACGAAGATTGCTGGCCGTGCGGTTGTTTTTACGCT\n",
      "pass  1005 68 149 81\n",
      "81\n",
      "81\n",
      "CTAGGAGTCGAGATCCATGATGTGTGCACTTGCTTGGAACAACAGACGAAGATTGCTGGCCGTGCGGTTGTTTTTACGCTC\n",
      "pass  1006 67 149 82\n",
      "82\n",
      "82\n",
      "CTAGGAGTCGAGATCCATGATGTGTGCACTTGCTTGGAACAACAGACGAAGATTGCTGGCCGTGCGGTTGTTTTTACGCTCG\n",
      "pass  1007 66 149 83\n",
      "83\n",
      "83\n",
      "CTAGGAGTCGAGATCCATGATGTGTGCACTTGCTTGGAACAACAGACGAAGATTGCTGGCCGTGCGGTTGTTTTTACGCTCGT\n",
      "pass  1008 65 149 84\n",
      "84\n",
      "84\n",
      "CTAGGAGTCGAGATCCATGATGTGTGCACTTGCTTGGAACAACAGACGAAGATTGCTGGCCGTGCGGTTGTTTTTACGCTCGTT\n",
      "pass  1009 64 149 85\n",
      "85\n",
      "85\n",
      "CTAGGAGTCGAGATCCATGATGTGTGCACTTGCTTGGAACAACAGACGAAGATTGCTGGCCGTGCGGTTGTTTTTACGCTCGTTC\n",
      "pass  1010 63 149 86\n",
      "86\n",
      "86\n",
      "CTAGGAGTCGAGATCCATGATGTGTGCACTTGCTTGGAACAACAGACGAAGATTGCTGGCCGTGCGGTTGTTTTTACGCTCGTTCG\n",
      "pass  1011 62 149 87\n",
      "87\n",
      "87\n",
      "CTAGGAGTCGAGATCCATGATGTGTGCACTTGCTTGGAACAACAGACGAAGATTGCTGGCCGTGCGGTTGTTTTTACGCTCGTTCGC\n",
      "pass  1012 61 149 88\n",
      "88\n",
      "88\n",
      "CTAGGAGTCGAGATCCATGATGTGTGCACTTGCTTGGAACAACAGACGAAGATTGCTGGCCGTGCGGTTGTTTTTACGCTCGTTCGCG\n",
      "pass  1013 60 149 89\n",
      "89\n",
      "89\n",
      "CTAGGAGTCGAGATCCATGATGTGTGCACTTGCTTGGAACAACAGACGAAGATTGCTGGCCGTGCGGTTGTTTTTACGCTCGTTCGCGC\n",
      "pass  1014 59 149 90\n",
      "90\n",
      "90\n",
      "CTAGGAGTCGAGATCCATGATGTGTGCACTTGCTTGGAACAACAGACGAAGATTGCTGGCCGTGCGGTTGTTTTTACGCTCGTTCGCGCA\n",
      "pass  1015 58 149 91\n",
      "91\n",
      "91\n",
      "CTAGGAGTCGAGATCCATGATGTGTGCACTTGCTTGGAACAACAGACGAAGATTGCTGGCCGTGCGGTTGTTTTTACGCTCGTTCGCGCAA\n",
      "pass  1016 57 149 92\n",
      "92\n",
      "92\n",
      "CTAGGAGTCGAGATCCATGATGTGTGCACTTGCTTGGAACAACAGACGAAGATTGCTGGCCGTGCGGTTGTTTTTACGCTCGTTCGCGCAAG\n",
      "pass  1017 56 149 93\n",
      "93\n",
      "93\n",
      "CTAGGAGTCGAGATCCATGATGTGTGCACTTGCTTGGAACAACAGACGAAGATTGCTGGCCGTGCGGTTGTTTTTACGCTCGTTCGCGCAAGC\n",
      "pass  1018 55 149 94\n",
      "94\n",
      "94\n",
      "CTAGGAGTCGAGATCCATGATGTGTGCACTTGCTTGGAACAACAGACGAAGATTGCTGGCCGTGCGGTTGTTTTTACGCTCGTTCGCGCAAGCA\n",
      "pass  1019 54 149 95\n",
      "95\n",
      "95\n",
      "CTAGGAGTCGAGATCCATGATGTGTGCACTTGCTTGGAACAACAGACGAAGATTGCTGGCCGTGCGGTTGTTTTTACGCTCGTTCGCGCAAGCAG\n",
      "pass  1020 53 149 96\n",
      "96\n",
      "96\n",
      "CTAGGAGTCGAGATCCATGATGTGTGCACTTGCTTGGAACAACAGACGAAGATTGCTGGCCGTGCGGTTGTTTTTACGCTCGTTCGCGCAAGCAGG\n",
      "1021 80832 80737\n",
      "1021 52 149 97\n",
      "97\n",
      "96\n",
      "CTAGGAGTCGAGATCCATGATGTGTGCACTTGCTTGGAACAACAGACGAAGATTGCTGGCCGTGCGGTTGTTTTTACGCTCGTTCGCGCAAGCAGG\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (96) into shape (97)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 44, in mapstar\n    return list(map(*args))\n  File \"<ipython-input-18-d484b995babe>\", line 64, in image_pileup_Parallelism\n    pre_pre_image_char_matrix[(i+1), image_read_fill_start:image_read_fill_end] = np.array(list(to_use_selected_scaffold_df[\"refined read\"][reads][:read_fill_end]))\nValueError: could not broadcast input array from shape (96) into shape (97)\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-973a28466720>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# termite_g2.sam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcolor_encoding_combination\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mONLY_CONSIDER_READ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-1ac3c59d396e>\u001b[0m in \u001b[0;36mcolor_encoding_combination\u001b[0;34m(ONLY_CONSIDER_READ, ALL_TOUCH_INCLUDED, window, depth, expand, core)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ERROR! If consider read of scaffold, depth must set to be 2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mconsider_read_of_scaffold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfasta_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminimum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mALL_TOUCH_INCLUDED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mconsider_only_scaffold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfasta_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminimum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mALL_TOUCH_INCLUDED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-064678ba149f>\u001b[0m in \u001b[0;36mconsider_read_of_scaffold\u001b[0;34m(fasta_df, sam, minimum, maximum, core, ALL_TOUCH_INCLUDED, window, depth, expand, ONLY_FILL_THE_LONGEST)\u001b[0m\n\u001b[1;32m     74\u001b[0m                                      \u001b[0mmapping_quality_not_provide\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                                      \u001b[0mon_positive_strand_not_provide\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                                      not_match_ref, core)\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0mend_time_temp\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" | Duration: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_time_temp\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-d484b995babe>\u001b[0m in \u001b[0;36mimage_pileup\u001b[0;34m(scaffold_name, fasta_df, read_selected_matrix, to_use_selected_scaffold_df, window, depth, skip_range, searching_interval, pixel_max, bias_of_read, mapping_quality_not_provide, on_positive_strand_not_provide, not_match_ref, core)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Pool()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_pileup_Parallelism\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaffold_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfasta_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_use_selected_scaffold_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_selected_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_positive_strand_not_provide\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mpre_image_base_color_locus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_image_mapping_quality_locus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_image_on_positive_strand_locus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpre_image_match_ref_locus\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearching_interval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0mpre_image_base_color\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre_image_base_color_locus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mpre_image_mapping_quality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre_image_mapping_quality_locus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         '''\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (96) into shape (97)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pass  999 74 149 75\n",
      "75\n",
      "75\n",
      "CTAGGAGTCGAGATCCATGATGTGTGCACTTGCTTGGAACAACAGACGAAGATTGCTGGCCGTGCGGTTGTTTTT\n"
     ]
    }
   ],
   "source": [
    "# termite_genome2.fasta\n",
    "# termite_g2.sam\n",
    "\n",
    "color_encoding_combination(ONLY_CONSIDER_READ = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Start color encoding\n",
    "## Version: consider expand of reads on scaffold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store data to pickle(serialize)\n",
    "with open(\"termite_g2_scaffold_image_dict_1500K_1550K.pickle\", \"wb\") as handle:\n",
    "    pickle.dump(scaffold_image_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store data (serialize)\n",
    "with open(\"scaffold_image_dict_v1.pickle\", \"wb\") as handle:\n",
    "    pickle.dump(scaffold_image_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data (deserialize)\n",
    "with open(\"termite_g2_scaffold_image_dict_1000K_1030K_fragment.pickle\", \"rb\") as handle:\n",
    "    unserialized_data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8150\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABrcAAABFCAYAAADggb3OAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAD3pJREFUeJzt3XmwJWV5x/Hvjxl2hgAOomzOoMTUaBR14hKtBHEDnDhWtAxIDGqUSoxxKRNlKaMmxmgl0WgJJgQIaAho4UapGNcUpozEAUUUBScwyCAI44KAERx48kf3hONl7nIu99zuc+73U3VqTvfb/d6n+/Yzb5/z3O5OVSFJkiRJkiRJkiSNgx26DkCSJEmSJEmSJEmaK4tbkiRJkiRJkiRJGhsWtyRJkiRJkiRJkjQ2LG5JkiRJkiRJkiRpbFjckiRJkiRJkiRJ0tiwuCVJkiRJkiRJkqSxYXFLkiRJkiRJkiRJY8PiliRJkqQlIcmmJE/vOo6FkmSfJB9M8sMkW5Kcm2TPgfa/SnJFkq1J3jxl3cOT3JPk9oHX8VP6/miSO5Jcl+SFi7hpkiRJkjQji1uSJEmSNJ7eCuwNrAYeCuwHvHmgfSPweuCT06z//araY+B1zkDbqcBdbZ/HAe9L8ogFjl+SJEmS5sXiliRJkqQlL8nLk2xM8qMkFybZf6DtEUk+27b9IMnJ7fyzk7x1YLnDk2wemH5DkhuS3JbkqiRPW+CwVwMfq6qfVtWtwEeB/y9AVdU5VXURcNswnSbZHXge8Maqur2q/hO4EHjRwoUuSZIkSfNncUuSJEnSkpbkCOBvgBcADwauA85v21YAnwM+DewPPAz4/Bz6fDjwSuA3qmoF8Cxg0zTLnpjkJ9O9ZvgxpwLrkuydZG+agtRFc9roxgPbYt21Sd7VFrUAfhXYWlVXDyx7OQOFM0mSJEnqksUtSZIkSUvdccBZVXVZVd0JnAQ8KckqYB1wU1X9fVX9vKpuq6pL5tDn3cDOwJokO1bVpqr6n+0tWFVvr6q9pnvN8DMuA3YCfti+7gZOm+M2fwc4jKaYdwTwOOCdbdsewE+nLH8rsGKOfUuSJEnSSFnckiRJkrTU7U9ztRYAVXU7TbHoAOAgYLtFqZlU1UbgNTTPwLo5yfmDtzpcIB8CrqYpOu1JE+e/zjG+m6rqyqq6p6qupXk21/Pa5tvb/gbtyZC3N5QkSZKkUbG4JUmSJGmp+z7wkG0T7e35HgDcAFwPHDLNencAuw1MP2iwsar+raqe0vZdwDu210mSk5PcPt1rhrgPA/6pqu5oC3L/CBw945ZOr7j38+HVwPIkhw60Pxr41jz7liRJkqQFZXFLkiRJ0lKyY5JdBl7LgfOAlyQ5LMnOwNuAS6pqE/AJ4MFJXpNk5yQrkjyh7evrwNFJ9knyIJortYDmmVtJjmj7+znwv8A92wuoqt5WVXtM95phW74KvCzJrkl2BU4AvjEQw45JdqH53Le83d5lbdtTkzwkjYOAtwMfb+O5A/gI8JdJdk/yZGA98IEh9rMkSZIkjYzFLUmSJElLyadoCk3bXm+uqs8BbwQ+DNwIPBQ4BqCqbgOeAfwOcBPwXeCpbV8fAC4HNgGfAT448HN2pikYbWnXeyDNs7wW0kuBVcBmmqvMDgGOH2j/Z5ptPBY4pX3/orbtMcCXaa4++zJwBfCqgXVfAewK3ExT/PvjqvLKLUmSJEm9kKrqOgZJkiRJkiRJkiRpTrxyS5IkSZIkSZIkSWPD4pYkSZIkSZIkSZLGhsUtSZIkSZIkSZIkjQ2LW5IkSZIkSZIkSRoby7sOYNAuK1fWilWr5rTswUP0+715RTM3xrE4RrV9w/Q76r7HKYY+GdX+GMf93Id9Mcq+xzHmUcUwrHE8nocx6cdRX34n4xjzMPpynjaMvpzTTfqxP4y+bN+kHxujMsrPBsMYt/0G4xnzMPryuXEp7Ls+6ENuw+QfR304f+jL+f4omYPz05fztL58juhDvi4Fffm/bhijimPLpZduqap9Z1uuV8WtFatW8dwNG+a07GlD9PuK+YUzJ8axOEa1fcP0O+q+xymGPhnV/hjH/dyHfTHKvscx5lHFMKxxPJ6HMenHUV9+J+MY8zD6cp42jL6c0036sT+MvmzfpB8bozLKzwbDGLf9BuMZ8zD68rlxKey7PuhDbsPkH0d9OH/oy/n+KJmD89OX87S+fI7oQ74uBX35v24Yo4rjjOS6uSznbQklSZIkSZIkSZI0NkZa3EpyZJKrkmxMcuIof5YkSZIkSZIkSZIm34zFrSS7JDk+yXPSeEOSTyR5d5KVs6y7DDgVOApYAxybZM3ChS5JkiRJkiRJkqSlZrYrt94PPBN4KfAfNM8Iey9wG3D2LOs+HthYVddU1V3A+cD6+xOsJEmSJEmSJEmSlrbls7SvqapHJlkObK6q327nfzrJ5bOsewBw/cD0ZuAJUxdKcgJwAsAeBx88t6glSZIkSZIkSZK0JM125dZdAFW1Ffj+lLa7FyKAqjq9qtZW1dpd9t13IbqUJEmSJEmSJEnShJrtyq0Dk7wHyMB72ukDZln3BuCgwb7aeZIkSZIkSZIkSdK8zFbc+vOB9xumtE2dnuqrwKFJVtMUtY4BXjhceJIkSZIkSZIkSdK9ZixuVdU58+24qrYmeSXw78Ay4Kyq+tZ8+5MkSZIkSZIkSZJmLG4leQpwSFW9v52+ANinbX5rVX1hpvWr6lPAp+YazBbgjDkuO9flRs04Fseotm+U+60Pv5M+xNAn43gcjco4HvvjGPMw+hAD9CeOURnH42gcfyfjGPMonVa3dh2CJEmSJEkTZbbbEr4F+NOB6YcDLwZ2B04GZixuSZIkSZIkSZIkSQtph1na96yqKwemv1tVl1bVxcCKEcYlSZIkSZIkSZIk3cdsxa29Bieq6ncHJvebacUkZyW5Ock35xucJEmSJEmSJEmSNGi24tZ3kjx76swk64CrZln3bODIecYlSZIkSZIkSZIk3cdsz9x6LfDJJM8HLmvnPQ74TWDdTCtW1cVJVt3fACVJkiRJkiRJkqRtZrxyq6o2Ao8CvgSsal8XA4+qqqsXIoAkJyTZkGQDt9yyEF1KkiRJkiRJkiRpQs125RZVdSdw1uC8JDskOa6qzr2/AVTV6cDpAFm7tu5vf5IkSZIkSZIkSZpcM165lWTPJCcleW+SZ6TxSuAa4AWLE6IkSZIkSZIkSZLUmO3KrQ8APwb+C3g5cAoQ4LlV9fURxyZJkiRJkiRJkiT9ktmKW4dU1a8DJDkDuBE4uKp+PlvHSc4DDgdWJtkMvKmqzryf8UqSJEmSJEmSJGkJm6249Yttb6rq7iSb51LYapc/9n5FJkmSJEmSJEmSJE2Rqpq+MbkbuGPbJLAr8LP2fVXVngsaTHILcN2U2SuBLQv5cyQNxRyUumUOSt0x/6RumYNSt8xBqTvmn9Qtc7BbD6mqfWdbaMbiVh8k2VBVa7uOQ1qqzEGpW+ag1B3zT+qWOSh1yxyUumP+Sd0yB8fDDl0HIEmSJEmSJEmSJM2VxS1JkiRJkiRJkiSNjXEobp3edQDSEmcOSt0yB6XumH9St8xBqVvmoNQd80/qljk4Bnr/zC1JkiRJkiRJkiRpm3G4ckuSJEmSJEmSJEkCLG5JkiRJkiRJkiRpjPS6uJXkyCRXJdmY5MSu45EmWZKDknwxyZVJvpXk1e38fZJ8Nsl323/37jpWaZIlWZbka0k+0U6vTnJJOxZ+MMlOXccoTaokeyW5IMl3knw7yZMcB6XFkeS17TnoN5Ocl2QXx0BpdJKcleTmJN8cmLfdMS+N97S5+I0kj+0ucmkyTJODf9ueh34jyUeT7DXQdlKbg1cleVY3UUuTY3s5OND2uiSVZGU77TjYU70tbiVZBpwKHAWsAY5NsqbbqKSJthV4XVWtAZ4I/EmbcycCn6+qQ4HPt9OSRufVwLcHpt8BvKuqHgb8GPjDTqKSloZ3A5+uql8DHk2Ti46D0oglOQB4FbC2qh4JLAOOwTFQGqWzgSOnzJtuzDsKOLR9nQC8b5FilCbZ2dw3Bz8LPLKqHgVcDZwE0H43cwzwiHad09rvTSXN39ncNwdJchDwTOB7A7MdB3uqt8Ut4PHAxqq6pqruAs4H1ncckzSxqurGqrqsfX8bzRd6B9Dk3TntYucAz+0mQmnyJTkQeDZwRjsd4AjggnYRc1AakSS/AvwWcCZAVd1VVT/BcVBaLMuBXZMsB3YDbsQxUBqZqroY+NGU2dONeeuB91fjK8BeSR68OJFKk2l7OVhVn6mqre3kV4AD2/frgfOr6s6quhbYSPO9qaR5mmYcBHgX8HqgBuY5DvZUn4tbBwDXD0xvbudJGrEkq4DHAJcA+1XVjW3TTcB+HYUlLQX/QHMSdU87/QDgJwMfcBwLpdFZDdwC/Et7a9AzkuyO46A0clV1A/B3NH8heyNwK3ApjoHSYptuzPP7GWnxvRS4qH1vDkqLIMl64IaqunxKkznYU30ubknqQJI9gA8Dr6mqnw62VVXxy3+5IGmBJFkH3FxVl3Ydi7RELQceC7yvqh4D3MGUWxA6Dkqj0T7XZz1NkXl/YHe2c5sYSYvHMU/qTpJTaB4dcW7XsUhLRZLdgJOBv+g6Fs1dn4tbNwAHDUwf2M6TNCJJdqQpbJ1bVR9pZ/9g26W27b83dxWfNOGeDDwnySaaW/EeQfP8n73aWzSBY6E0SpuBzVV1STt9AU2xy3FQGr2nA9dW1S1V9QvgIzTjomOgtLimG/P8fkZaJEleDKwDjmuLzGAOSovhoTR/aHV5+73MgcBlSR6EOdhbfS5ufRU4NMnqJDvRPDjxwo5jkiZW+2yfM4FvV9U7B5ouBI5v3x8PfHyxY5OWgqo6qaoOrKpVNGPeF6rqOOCLwPPbxcxBaUSq6ibg+iQPb2c9DbgSx0FpMXwPeGKS3dpz0m355xgoLa7pxrwLgT9I44nArQO3L5S0QJIcSXOb+udU1c8Gmi4Ejkmyc5LVwKHAf3cRozSpquqKqnpgVa1qv5fZDDy2/ZzoONhTufePAPonydE0zx9ZBpxVVX/dcUjSxEryFOBLwBXc+7yfk2meu/Uh4GDgOuAFVbW9By5KWiBJDgf+rKrWJTmE5kqufYCvAb9fVXd2GZ80qZIcBpwB7ARcA7yE5o/BHAelEUvyFuD3aG7D9DXgZTTPMnAMlEYgyXnA4cBK4AfAm4CPsZ0xry06v5fmdqE/A15SVRu6iFuaFNPk4EnAzsAP28W+UlV/1C5/Cs1zuLbSPEbioql9Spq77eVgVZ050L4JWFtVWxwH+6vXxS1JkiRJkiRJkiRpUJ9vSyhJkiRJkiRJkiT9EotbkiRJkiRJkiRJGhsWtyRJkiRJkiRJkjQ2LG5JkiRJkiRJkiRpbFjckiRJkiRJkiRJ0tiwuCVJkiRJkiRJkqSxYXFLkiRJkiRJkiRJY+P/AKeXslUtGe3mAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 2160x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 3600x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 4320x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/cAAABqCAYAAAD5lqHPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADi9JREFUeJzt3X2wXVV5x/HvzwQQUN5MipAEAkhxkIERMwIy03aQtiA2qYgCBbEtHWxHizB0rNiZtuP0DwUGfKNOkXelUEA6BlprKVWZYQomBIgQiMTwFooSfAELFUj69I+zIdeQc88OZN97zz3fz8yZe9ba+9zzzNxn1j3P2WutnapCkiRJkiQNr9dNdgCSJEmSJOm1sbiXJEmSJGnIWdxLkiRJkjTkLO4lSZIkSRpyFveSJEmSJA05i3tJkiRJkoacxb0kSZIkSUPO4l6SJEmSpCE3s9+BJDcC1e94VS3sJCJJkiRJkrRZ+hb3wHnNz2OBNwNfa9onAj/uMihJkiRJktReqvpenO+dkCytqgWD+iRJkiRJ0uRos+Z++yR7v9RIshewfXchSZIkSZKkzTHetPyXnAl8J8lqIMCewEc6jUqSJEmSJLU2cFo+QJJtgLc2zQeq6vlOo5IkSZIkSa21Le7fBcxnzJX+qrqyu7AkSZIkSVJbA6flJ/kqsA9wN7C+6S7A4l6SJEmSpCmgzW759wP7V5tL/JIkSZIkacK12S3/Xnr3uZckSZIkSVNQm93yZwErknwPeHkjvapa2FlUkiRJkiSptTbF/d92HYQkSZIkSXr1Wu2WL0mSJEmSpq6Ba+6THJpkSZL/SfJCkvVJnpmI4CRJkiRJ0mBtNtT7EnAi8CCwLfAnwIVdBiVJkiRJktprU9xTVauAGVW1vqouA47qNixJkiRJktRWmw31nkuyNXB3knOAJ2j5pYAkSZIkSepemyL9Q815HwOeBeYB7+8yKEmSJEmS1N64u+UnmQFcWVUnTVxIkiRJkiRpc4x75b6q1gN7NtPyJUmSJEnSFNRmzf1q4LYki+lNywegqs7vLCpJkiRJktRam+L+h83jdcAbm77+c/klSZIkSdKEalPcr6iq68Z2JPlAR/FIkiRJkqTNNO6GegBJllXVwYP6JEmSJEnS5Oh75T7J0cB7gDlJvjDm0A7Auq4DkyRJkiRJ7Yw3Lf+/gaXAQuDOMf2/AM7sMihJkiRJktRem2n5W1XVi83znYF5VbV8IoKTJEmSJEmDjXuf+8bNSXZIsguwDPhKkgs6jkuSJEmSJLXUprjfsaqeAY4FrqyqQ4B3dxuWJEmSJElqq01xPzPJbsAHgZs6jkeSJEmSJG2mNsX9p4FvAauqakmSvYEHuw1LkiRJkiS1NXBDPUmSJEmSNLW1uXIvSZIkSZKmMIt7SZIkSZKGnMW9JEmSJElDbmBxn2TXJJck+WbT3j/Jqd2HJkmSJEmS2mhz5f5yervl7960fwCc0VVAkiRJkiRp88xscc6sqro2ydkAVbUuyfo2vzzJUcDngRnAxVX1mXHfaNasmj9/fptfLUmSJEnStPfwww/z1FNPZdB5bYr7Z5O8CSiAJIcCTw96UZIZwIXAbwNrgCVJFlfVin6vmT9/PkuXLm0RkiRJkiRJ09+CBQtandemuD8LWAzsk+Q2YDZwXIvXvRNYVVWrAZJcAywC+hb3kiRJkiRp8w0s7qvqziS/CewHBFhZVS+2+N1zgMfGtNcAh7yqKCVJkiRJUl9tdstfDnwC+GVV3duysG8tyWlJliZZunbt2i35qyVJkiRJGgltdsv/PWAdcG2SJUn+IskeLV73ODBvTHtu0/crquqiqlpQVQtmz57dKmhJkiRJkrTBwOK+qh6pqnOq6h3AHwAHAg+1+N2nAUcmWZlka+AEemv3JUmSJEnSFtRmQz2S7Akc3zzW05umP8hlwDLgPOB+4NKquu9VxilJUmvJwLvFSJIkTSsDi/skdwBbAdcBH3hp9/tBqurWJI8CH6mqA15bmJIkSZIkqZ82V+5PqaqVnUciSZIkSZJelb7FfZKTq+prwDFJjtn4eFWdvyUCSHIavfX57LFHm336JEmSJEnSWONtqLd98/ONm3i8YUsF4G75kiRJkiS9Nn2v3FfVPzRP/6Oqbht7LMnhnUYlSZIkSZJaa3Of+y+27PsVSa4G/gvYL8maJKdubnCSJEmSJGmwVNWmDySHAe8CzgAuGHNoB+B9VXXQFg8mWQs80jRnAU9t6ffQ0DEPBOaBNjAXBOaBeswDgXmgDaZzLuxZVQPXsI+3W/7W9NbWz6S3zv4lzwDHvbbYNm1swEmWVtWCLt5Hw8M8EJgH2sBcEJgH6jEPBOaBNjAXxl9z/13gu0kur6pH+p0nSZIkSZIm13i3wvtcVZ0BfCnJK+buV9XCTiOTJEmSJEmtjDct/6vNz/MmIpBNuGiS3ldTi3kgMA+0gbkgMA/UYx4IzANtMPK50HdDvU2enOwMzKuq5d2FJEmSJEmSNsfAW+El+U6SHZLsAiwDvpLk/O5DkyRJkiRJbbS5z/2OVfUMcCxwZVUdAhzZVUBJjkqyMsmqJJ/s6n009SSZl+TbSVYkuS/Jx5v+XZLcnOTB5ufOkx2rupdkRpK7ktzUtPdKckczNvxTkq0nO0Z1K8lOSa5P8kCS+5Mc5ngwepKc2fxPuDfJ1Ule73gwGpJcmuTJJPeO6dvkGJCeLzQ5sTzJwZMXubakPnlwbvO/YXmSf06y05hjZzd5sDLJ705O1NrSNpUHY46dlaSSzGraIzsetCnuZybZDfggcFOXwSSZAVwIHA3sD5yYZP8u31NTyjrgrKraHzgU+Gjz9/8kcEtV7Qvc0rQ1/X0cuH9M+7PABVX1FuBnwKmTEpUm0ueBf6uqtwIH0csHx4MRkmQOcDqwoKoOAGYAJ+B4MCouB47aqK/fGHA0sG/zOA348gTFqO5dzivz4GbggKo6EPgBcDZA87nxBOBtzWv+vqkvNPwu55V5QJJ5wO8Aj47pHtnxoE1x/2ngW8APq2pJkr2BBzuK553AqqpaXVUvANcAizp6L00xVfVEVS1rnv+C3gf5OfRy4IrmtCuA35+cCDVRkswFjgEubtoBjgCub04xD6a5JDsCvwFcAlBVL1TVz3E8GEUzgW2TzAS2A57A8WAkVNWtwE836u43BiyiN8O0qup2YKfm4pSG3KbyoKr+varWNc3bgbnN80XANVX1fFU9BKyiV19oyPUZDwAuAD4BjN1IbmTHg4HFfVVdV1UHVtWfNe3VVfX+juKZAzw2pr2m6dOISTIfeDtwB7BrVT3RHPoRsOskhaWJ8zl6A/X/Ne03AT8f84/csWH62wtYC1zWLM+4OMn2OB6MlKp6nN5dex6lV9Q/DdyJ48Eo6zcG+BlydP0x8M3muXkwQpIsAh6vqns2OjSyedBmQ725zVqWJ5vH15uralInkrwB+DpwRrPfw8uqd3uH9rd40NBJ8l7gyaq6c7Jj0aSaCRwMfLmq3g48y0ZT8B0Ppr9mPfUiel/27A5szyamZWo0OQYoyV/RW9Z51WTHoomVZDvgU8BfT3YsU0mbafmXAYvp/VPdHbix6evC48C8Me25TZ9GRJKt6BX2V1XVDU33j1+aStP8fHKy4tOEOBxYmORhektzjqC39nqnZlouODaMgjXAmqq6o2lfT6/YdzwYLUcCD1XV2qp6EbiB3hjheDC6+o0BfoYcMUn+EHgvcFJtuLe3eTA69qH3xe89zWfGucCyJG9mhPOgTXE/u6ouq6p1zeNyYHZH8SwB9m12wd2a3oYYizt6L00xzbrqS4D7q2rs7RYXAx9unn8Y+MZEx6aJU1VnV9XcqppPbwz4z6o6Cfg2cFxzmnkwzVXVj4DHkuzXdL0bWIHjwah5FDg0yXbN/4iX8sDxYHT1GwMWA6c0u2QfCjw9Zvq+ppkkR9Fbvrewqp4bc2gxcEKSbZLsRW9Dte9NRozqVlV9v6p+rarmN58Z1wAHN58fRnY8mDn4FH6S5GTg6qZ9IvCTLoKpqnVJPkZvA78ZwKVVdV8X76Up6XDgQ8D3k9zd9H0K+AxwbZJTgUfo3blBo+cvgWuS/B1wF81Ga5rW/hy4qvmydzXwR/S+lHY8GBFVdUeS64Fl9Kbe3gVcBPwLjgfTXpKrgd8CZiVZA/wN/T8T/CvwHnobqD1Hb7zQNNAnD84GtgFu7n3vx+1V9adVdV+Sa+l9CbgO+GhVrZ+cyLUlbSoPqqrf2D+y40E2zGLpc0KyJ/BF4LCm6zbg9Kp6tP+rJEmSJEnSRBlY3EuSJEmSpKmtzW75eye5McnaZrf8bzT3upckSZIkSVNAmw31/hG4FtiN3m7517Fh/b0kSZIkSZpkbdbcL6+qAzfqu6eqDuo0MkmSJEmS1Eqb4v6zwM/o3W+6gOOBnYFzAarqpx3HKEmSJEmSxtGmuH9onMNVVa6/lyRJkiRpErlbviRJkiRJQ67NhnqSJEmSJGkKs7iXJEmSJGnIWdxLkiRJkjTkZrY5KckcYM+x51fVrV0FJUmSJEmS2htY3De3wjseWAGsb7oLsLiXJEmSJGkKaHMrvJXAgVX1/MSEJEmSJEmSNkebNferga26DkSSJEmSJL06bdbcPwfcneQW4OWr91V1emdRSZIkSZKk1toU94ubhyRJkiRJmoLarLl/PfCWprmqqn7ZeVSSJEmSJKm1vmvuk8xMcg6wBrgCuBJ4LMk5SVyDL0mSJEnSFDHehnrnArsAe1XVO6rqYGAfYCfgvIkITpIkSZIkDdZ3Wn6SB4Ffr41OSDIDeKCq9p2A+CRJkiRJ0gDjXbmvjQv7pnM9MP5CfUmSJEmSNGHGK+5XJDll484kJwMPdBeSJEmSJEnaHONNy58D3AD8L3Bn070A2BZ4X1U9PiERSpIkSZKkcbW5Fd4RwNua5oqquqXzqCRJkiRJUmsDi3tJkiRJkjS1jbfmXpIkSZIkDQGLe0mSJEmShpzFvSRJkiRJQ87iXpIkSZKkIWdxL0mSJEnSkPt/ar1TCr036v4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 5760x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = unserialized_data['scaffold161|size1025551|543642 to 552805']\n",
    "visualization_locus(8150, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
